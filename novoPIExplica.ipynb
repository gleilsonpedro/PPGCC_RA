{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [-0.39381403  0.96220565 -2.37519275 -0.99872731]\n",
      "Delta: [-0.7088652578943643, 1.539529034488898, -8.788213178604362, -1.098600036798368]\n",
      "Limiar R: 9.06\n",
      "{'sepal length (cm)': 6.1, 'sepal width (cm)': 2.8, 'petal length (cm)': 4.7, 'petal width (cm)': 1.2}\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target #rotulos\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "w = modelo.coef_[0] # pesos do modelo treinado\n",
    "Vs = X_test.iloc[0].to_dict() # utilizxando a primeira instância dos dados de teste \n",
    "\n",
    "# Inicializa a lista para armazenar os deltas\n",
    "# o delta c\\ peso negativo é (valor feature na instancia - valor min da feature no dataset) * o peso da feature \n",
    "# o delta c\\ peso positivo é (vvalor max da feature no dataset - valor feature na instancia - ) * o peso da feature\n",
    "delta = []\n",
    "\n",
    "\n",
    "# Calcula o valor delta para cada feature\n",
    "# peso negativo, valor menor = maior possibilidade da instância peetencer a classe\n",
    "for i, feature in enumerate(df.columns[:-1]):  \n",
    "    if w[i] < 0:\n",
    "        delta.append((Vs[feature] - df[feature].min()) * w[i])\n",
    "    else:\n",
    "        delta.append((df[feature].max() - Vs[feature]) * w[i])\n",
    "\n",
    "# Calcula o limiar (-Gamma_w)\n",
    "R = abs(-sum(delta))  # Usando a equação 13 do artigo e garantindo que R seja positivo\n",
    "\n",
    "print(f\"Pesos: {w}\")\n",
    "print(f\"Delta: {delta}\")\n",
    "print(f\"Limiar R: {R:.2f}\")\n",
    "print(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_explanation(Vs, delta, R):\n",
    "    Xpl = []  # Inicializa a lista de PI-explicação\n",
    "    delta_sorted = sorted(delta, reverse=True) # Ordena os valores delta em ordem decrescente\n",
    "    R_atual = R # Inicializa o limiar atual\n",
    "    Idx = 0 # Itera sobre os valores delta ordenados\n",
    "   \n",
    "    while R_atual >= 0:\n",
    "        feature = X_test.columns[Idx] # nome da feature correspondente ao índice\n",
    "        Xpl.append(feature) # Adiciona a feature à PI-explicação\n",
    "        R_atual -= delta_sorted[Idx] # Atualiza o limiar atual\n",
    "        Idx += 1 # Incrementa o índice\n",
    "    \n",
    "    return Xpl # Retorna a PI-explicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Computa a PI-explicação\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Xpl \u001b[38;5;241m=\u001b[39m \u001b[43mone_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Imprime a PI-explicação\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI-Explicação: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXpl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m, in \u001b[0;36mone_explanation\u001b[1;34m(Vs, delta, R)\u001b[0m\n\u001b[0;32m      5\u001b[0m Idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Itera sobre os valores delta ordenados\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m R_atual \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 8\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mIdx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# nome da feature correspondente ao índice\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     Xpl\u001b[38;5;241m.\u001b[39mappend(feature) \u001b[38;5;66;03m# Adiciona a feature à PI-explicação\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     R_atual \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m delta_sorted[Idx] \u001b[38;5;66;03m# Atualiza o limiar atual\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5363\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5361\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5362\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 5363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5366\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5367\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5368\u001b[0m     result \u001b[38;5;241m=\u001b[39m getitem(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "# Computa a PI-explicação\n",
    "Xpl = one_explanation(Vs, delta, R)\n",
    "\n",
    "# Imprime a PI-explicação\n",
    "print(f\"PI-Explicação: {Xpl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(delta)) \u001b[38;5;66;03m# Usando a equação 13 do artigo e garantindo que R seja positivo\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Computa a PI-explicação\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m Xpl \u001b[38;5;241m=\u001b[39m \u001b[43mone_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Imprime a PI-explicação\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPesos: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 63\u001b[0m, in \u001b[0;36mone_explanation\u001b[1;34m(Vs, w, df, R)\u001b[0m\n\u001b[0;32m     61\u001b[0m Idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Atualiza o limiar atual\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m R_atual \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdelta_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mIdx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Obtém o nome da feature correspondente ao índice\u001b[39;00m\n\u001b[0;32m     65\u001b[0m feature \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mcolumns[Idx]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target  # Rótulos\n",
    "\n",
    "# Divide o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina um modelo de regressão logística\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Obtém os pesos do modelo\n",
    "w = modelo.coef_[0]  # Pesos do modelo treinado\n",
    "\n",
    "def one_explanation(Vs, w, df, R):\n",
    "    \"\"\"\n",
    "    Função que computa uma única PI-explicação para um classificador linear,\n",
    "    seguindo a lógica do algoritmo do artigo.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância que está sendo explicada (como um dicionário).\n",
    "        w: Vetor de pesos para cada feature (como um dicionário).\n",
    "        df: DataFrame com os dados.\n",
    "        R: Limiar para a explicação (-Gamma_w).\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de features que representa a PI-explicação.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializa a lista de PI-explicação\n",
    "    Xpl = []\n",
    "\n",
    "    # Inicializa o limiar atual\n",
    "    R_atual = R\n",
    "\n",
    "    # Calcula os deltas para cada feature\n",
    "    delta = []\n",
    "    for i, feature in enumerate(df.columns[:-1]):\n",
    "        if w[i] < 0:\n",
    "            delta.append((Vs[feature] - df[feature].min()) * w[i])\n",
    "        else:\n",
    "            delta.append((df[feature].max() - Vs[feature]) * w[i])\n",
    "\n",
    "    # Ordena os valores delta em ordem decrescente\n",
    "    delta_sorted = sorted(delta, reverse=True)\n",
    "\n",
    "    # Calcula o limiar (-Gamma_w) -  Ajustado para garantir que R seja menor que a soma dos deltas\n",
    "    R_inicial = abs(-sum(delta))  # Usando a equação 13 do artigo e garantindo que R seja positivo\n",
    "\n",
    "    # Itera sobre os valores delta ordenados\n",
    "    Idx = 0\n",
    "    R_atual = R_inicial  # R_atual é inicializado com o limiar R_inicial\n",
    "    while R_atual >= 0:  # Ajusta a condição do loop\n",
    "        # Incrementa o índice\n",
    "        Idx += 1\n",
    "        # Atualiza o limiar atual\n",
    "        R_atual -= delta_sorted[Idx]\n",
    "        # Obtém o nome da feature correspondente ao índice\n",
    "        feature = X_test.columns[Idx]\n",
    "\n",
    "        # Adiciona a feature à PI-explicação\n",
    "        Xpl.append(feature)\n",
    "\n",
    "\n",
    "\n",
    "    # Retorna a PI-explicação\n",
    "    return Xpl\n",
    "\n",
    "# Seleciona uma instância do dataset de teste\n",
    "Vs = X_test.iloc[0].to_dict()  # Utilizando a primeira instância dos dados de teste \n",
    "\n",
    "# Calcula o limiar (-Gamma_w) -  Ajustado para garantir que R seja menor que a soma dos deltas\n",
    "R = abs(-sum(delta)) # Usando a equação 13 do artigo e garantindo que R seja positivo\n",
    "\n",
    "# Computa a PI-explicação\n",
    "Xpl = one_explanation(Vs, w, df, R)\n",
    "\n",
    "# Imprime a PI-explicação\n",
    "print(f\"Pesos: {w}\")\n",
    "print(f\"Delta: {delta}\")\n",
    "print(f\"Limiar R: {R:.2f}\")\n",
    "print(Vs)\n",
    "print(f\"PI-Explicação: {Xpl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_explanation(Vs, delta, R):\n",
    "    Xpl = [] # é a lista de pi-explicação\n",
    "    delta_sorted = sorted(delta, reverse=True) # Ordena os valores delta em ordem decrescente\n",
    "    R_atual = R # Inicializa o limiar atual\n",
    "    Idx = 0 # Itera sobre os valores delta ordenados\n",
    "    \n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        # Obtém o nome da feature correspondente ao índice\n",
    "        feature = X_test.columns[Idx]\n",
    "\n",
    "        # Adiciona a feature à PI-explicação\n",
    "        Xpl.append(feature)\n",
    "\n",
    "        # Atualiza o limiar atual\n",
    "        R_atual -= delta_sorted[Idx]\n",
    "\n",
    "        # Incrementa o índice\n",
    "        Idx += 1\n",
    "\n",
    "    # Retorna a PI-explicação\n",
    "    return Xpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_explanation(Vs, delta, R):\n",
    "\n",
    " \n",
    " Xpl = [] # é a lista de pi-explicação\n",
    "\n",
    "    # Ordena os valores delta em ordem decrescente\n",
    "    delta_sorted = sorted(delta, reverse=True)\n",
    "\n",
    "    # Inicializa o limiar atual\n",
    "    R_atual = R\n",
    "\n",
    "    # Itera sobre os valores delta ordenados\n",
    "    Idx = 0\n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        # Obtém o nome da feature correspondente ao índice\n",
    "        feature = X_test.columns[Idx]\n",
    "\n",
    "        # Adiciona a feature à PI-explicação\n",
    "        Xpl.append(feature)\n",
    "\n",
    "        # Atualiza o limiar atual\n",
    "        R_atual -= delta_sorted[Idx]\n",
    "\n",
    "        # Incrementa o índice\n",
    "        Idx += 1\n",
    "\n",
    "    # Retorna a PI-explicação\n",
    "    return Xpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def one_explanation(Vs, delta, R):\n",
    "    \"\"\"\n",
    "    Função que computa uma única PI-explicação para um classificador linear,\n",
    "    seguindo a lógica do algoritmo do artigo.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância que está sendo explicada (como um dicionário).\n",
    "        delta: Lista de valores delta para cada feature.\n",
    "        R: Limiar para a explicação (-Gamma_w).\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de features que representa a PI-explicação.\n",
    "    \"\"\"\n",
    "\n",
    "    Xpl = [] # é a lista de pi-explicação\n",
    "\n",
    "    # Ordena os valores delta em ordem decrescente\n",
    "    delta_sorted = sorted(delta, reverse=True)\n",
    "\n",
    "    # Inicializa o limiar atual\n",
    "    R_atual = R\n",
    "\n",
    "    # Itera sobre os valores delta ordenados\n",
    "    Idx = 0\n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        # Obtém o nome da feature correspondente ao índice\n",
    "        feature = X_test.columns[Idx]\n",
    "\n",
    "        # Adiciona a feature à PI-explicação\n",
    "        Xpl.append(feature)\n",
    "\n",
    "        # Atualiza o limiar atual\n",
    "        R_atual -= delta_sorted[Idx]\n",
    "\n",
    "        # Incrementa o índice\n",
    "        Idx += 1\n",
    "\n",
    "    # Retorna a PI-explicação\n",
    "    return Xpl\n",
    "\n",
    "def compute_delta(df, w, Vs):\n",
    "    \"\"\"\n",
    "    Função que computa o valor delta para cada feature, seguindo as regras do artigo.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame com os dados.\n",
    "        w: Vetor de pesos para cada feature (como um dicionário).\n",
    "        Vs: Valores da instância que está sendo explicada (como um dicionário).\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de valores delta para cada feature.\n",
    "    \"\"\"\n",
    "\n",
    "    delta = []\n",
    "    for feature in df.columns:\n",
    "        # Se o peso for negativo\n",
    "        if w[feature] < 0:\n",
    "            # Calcula o valor delta como (valor da instância - valor mínimo da feature) * peso da feature\n",
    "            delta.append((Vs[feature] - df[feature].min()) * w[feature])\n",
    "        else:\n",
    "            # Calcula o valor delta como (valor máximo da feature - valor da instância) * peso da feature\n",
    "            delta.append((df[feature].max() - Vs[feature]) * w[feature])\n",
    "\n",
    "    return delta\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Divide o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2)\n",
    "\n",
    "# Armazena os nomes das colunas originais\n",
    "colunas_originais = X_train.columns\n",
    "\n",
    "# Escalona os dados de treino e teste usando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Converte X_train e X_test de volta para DataFrames pandas\n",
    "X_train = pd.DataFrame(X_train, columns=colunas_originais)\n",
    "X_test = pd.DataFrame(X_test, columns=colunas_originais)\n",
    "\n",
    "# Treina um modelo de regressão logística\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtém os pesos do modelo\n",
    "w = dict(zip(X_train.columns, model.coef_[0]))\n",
    "\n",
    "# Seleciona uma instância do dataset de teste\n",
    "Vs = X_test.iloc[0].to_dict()\n",
    "\n",
    "# Calcula o valor delta para cada feature\n",
    "delta = compute_delta(df.drop('target', axis=1), w, Vs)\n",
    "\n",
    "# Calcula o limiar (-Gamma_w)\n",
    "R = -sum(delta)  # Usando a equação 13 do artigo\n",
    "\n",
    "# Computa a PI-explicação\n",
    "Xpl = one_explanation(Vs, delta, R)\n",
    "\n",
    "# Imprime a PI-explicação\n",
    "print(Xpl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
