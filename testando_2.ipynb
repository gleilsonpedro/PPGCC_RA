{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes identificadas pelo modelo: [0 1 2]\n",
      "Nomes das classes: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Número total de instâncias no conjunto de teste: 30\n",
      "0\n",
      "\n",
      "Instância 0:\n",
      "Classe verdadeira: 1 (versicolor)\n",
      "Probabilidades: [0.00380009 0.82771461 0.16848529]\n",
      "Valor de gamma_A: 0.8277146135745481\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'t'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# se o peso for negativo\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m         delta\u001b[38;5;241m.\u001b[39mappend((\u001b[43mVs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m df[feature]\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m*\u001b[39m w[i])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         delta\u001b[38;5;241m.\u001b[39mappend((df[feature]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m Vs[feature]) \u001b[38;5;241m*\u001b[39m w[i])\n",
      "\u001b[1;31mKeyError\u001b[0m: 't'"
     ]
    }
   ],
   "source": [
    "# análise completa com todas as instancias do dataset\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  # organizando em um DataFrame\n",
    "df['target'] = iris.target  # rótulos\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina o modelo\n",
    "modelo = LogisticRegression(max_iter=200)\n",
    "modelo.fit(X_train, y_train)  # Treinando o modelo\n",
    "\n",
    "# Exibe as classes identificadas pelo modelo\n",
    "classes = modelo.classes_\n",
    "print(f\"Classes identificadas pelo modelo: {classes}\")\n",
    "print(f\"Nomes das classes: {iris['target_names']}\")\n",
    "\n",
    "# Informações sobre o dataset\n",
    "num_instancias = len(X_test)\n",
    "print(f\"\\nNúmero total de instâncias no conjunto de teste: {num_instancias}\")\n",
    "\n",
    "# Escolher qual instância analisar ou todas\n",
    "# Escolha da instância específica (por exemplo, 0) ou `None` para todas\n",
    "instancia_para_analisar = 0  \n",
    "# Operador ternàrio - se a instancia for (None) salva todas na variavel, se não adiciona somente a instância escolhida\n",
    "instancias_para_analisar = range(num_instancias) if instancia_para_analisar is None else [instancia_para_analisar]\n",
    "print(instancia_para_analisar)\n",
    "# Loop para analisar instâncias\n",
    "for idx in instancias_para_analisar:\n",
    "    Vs = X_test.iloc[idx].to_dict()  # Utilizando a instância de teste especificada\n",
    "    instancia_test = X_test.iloc[[idx]]  # Mantém como DataFrame para preservar os nomes das características\n",
    "\n",
    "    # Previsão de probabilidades para a instância\n",
    "    probs = modelo.predict_proba(instancia_test)[0]  # Obtém as probabilidades para cada classe usando o 0 para acesar a 1ª linha\n",
    "\n",
    "    # O valor de gamma_A é a probabilidade da (classe verdadeira - é o rotulo original do dataset o qual pertence a instância)\n",
    "    classe_verdadeira = y_test.iloc[idx]  # Obtém a classe verdadeira da instância\n",
    "    gamma_A = probs[classe_verdadeira]  # Extrai a probabilidade correspondente à classe verdadeira treinada pela reg.logistica na func predict_proba\n",
    "\n",
    "    # Exibe a classe verdadeira e as probabilidades\n",
    "    print(f\"\\nInstância {idx}:\")\n",
    "    print(f\"Classe verdadeira: {classe_verdadeira} ({iris['target_names'][classe_verdadeira]})\")\n",
    "    print(f\"Probabilidades: {probs}\")\n",
    "    print(f\"Valor de gamma_A: {gamma_A}\")\n",
    "\n",
    "    # Cálculo dos deltas para cada feature\n",
    "    delta = []\n",
    "    w = modelo.coef_[0]  # Pesos do modelo treinado\n",
    "\n",
    "    for i, feature in enumerate(df.columns[-1]):\n",
    "        if w[i] < 0: # se o peso for negativo\n",
    "            delta.append((Vs[feature] - df[feature].min()) * w[i])\n",
    "        else:\n",
    "            delta.append((df[feature].max() - Vs[feature]) * w[i])\n",
    "\n",
    "    # Calcula R como a soma dos deltas menos gamma_A   #### no artigo não menciona se o R pode ou não ser negativo, R negativo sugere que as características                                         não estão explicando suficientemente a predição\n",
    "    \n",
    "    R = sum(delta) - gamma_A\n",
    "    #R = abs(sum(delta) - gamma_A) # a função abs alem de tratar o valor absoluto permite sempre o resultado ser positivo ou seja ela remove o simbolo negativo, porem acredito que está calculando errado\n",
    "\n",
    "    #R = max(0, sum(delta) - gamma_A)\n",
    "\n",
    "   \n",
    "    # Computa a PI-explicação\n",
    "    Xpl = []\n",
    "    delta_sorted = sorted(enumerate(delta), key=lambda x: abs(x[1]), reverse=True)\n",
    "    R_atual = R\n",
    "    Idx = 0\n",
    "\n",
    "    # Calcula a explicação\n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        sorted_idx, delta_value = delta_sorted[Idx]\n",
    "        feature = X_test.columns[sorted_idx]  # Nome da feature correspondente\n",
    "        feature_value = Vs[feature]  # Valor da feature para a instância\n",
    "\n",
    "        # Adiciona à explicação\n",
    "        Xpl.append(f\"{feature} - {feature_value}\")\n",
    "\n",
    "        R_atual -= delta_value\n",
    "        Idx += 1\n",
    "\n",
    "    # Imprime a PI-explicação\n",
    "    print(f\"Valor de R: {R}\")\n",
    "    print(\"PI-Explicação:\")\n",
    "    for item in Xpl:\n",
    "        print(f\"- {item}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
