{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Seleciona apenas duas features (sepal length e petal length)\n",
    "df = df[['sepal length (cm)', 'petal length (cm)', 'target']]\n",
    "# Filtra o dataframe para exibir somente as classes 0 e 1\n",
    "df = df[df['target'].isin([0, 1])] \n",
    "# Define as features R_eais\n",
    "R = [0, 1]  # Índices das features reais (sepal_length e petal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[0.40134407 2.70157992]]\n",
      "Intercepto: [-9.3407263]\n",
      "Acurácia: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Separa os dados em features (X) e classes (y)\n",
    "X = df.iloc[:, R]  # Seleciona as features reais\n",
    "y = df['target']\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cria o modelo de regressão logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Imprime os pesos encontrados\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "\n",
    "# Avalia o modelo com os dados de teste\n",
    "score = modelo.score(X_test, y_test)\n",
    "print(f\"Acurácia: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os pesos do classificador linear\n",
    "w1 = modelo.coef_[0][0]  # Peso para 'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso para 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        REPORTEXPLANATION(Xpl, classe, w1, w2)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # Conjunto de literais da explicação\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        while Idx >= 0 and Idx < len(delta):  # Adiciona a condição para verificar o limite de Idx\n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "    return pi_explicacoes\n",
    "\n",
    "def REPORTEXPLANATION(Xpl, classe, w1, w2):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    EXPLICAR_PI(Xpl, w1, w2, df)\n",
    "\n",
    "def EXPLICAR_PI(Xpl, w1, w2, df):\n",
    "    \"\"\"Explica os elementos da PI-explicação.\"\"\"\n",
    "    for item in Xpl:\n",
    "        idx, valores = eval(item)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "        else:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "        if idx == 0:\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 1.4, 0.0])'}\n",
      "  - Petal Width (2.7015799199369277): 1.4 cm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'petal width (cm)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'petal width (cm)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     Vs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(row))  \u001b[38;5;66;03m# Excluir a coluna target\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Chama a função para enumerar todas as PI-explicações\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pi_explicacoes \u001b[38;5;241m=\u001b[39m \u001b[43mALLEXPLANATIONS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Cria um DataFrame com as PI-explicações\u001b[39;00m\n\u001b[0;32m     22\u001b[0m pi_explicacoes_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(pi_explicacoes, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClasse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPI-Explicação\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[22], line 53\u001b[0m, in \u001b[0;36mALLEXPLANATIONS\u001b[1;34m(Vs, delta, threshold, w1, w2)\u001b[0m\n\u001b[0;32m     51\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m Idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(delta):  \u001b[38;5;66;03m# Adiciona a condição para verificar o limite de Idx\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     R, Idx \u001b[38;5;241m=\u001b[39m \u001b[43mONEEXPLANATION\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Ajuste para garantir que R não se torne negativo\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m R \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m, in \u001b[0;36mONEEXPLANATION\u001b[1;34m(Vs, delta, R, Idx, Xpl, classe)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Converte a tupla para string para que seja \"hashable\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     Xpl\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mstr\u001b[39m((Idx, Vs[Idx])))  \u001b[38;5;66;03m# Adiciona o literal à PI-explicação\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mREPORTEXPLANATION\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Imprime ou processa a PI-explicação atual\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m R, Idx\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Se Idx estiver fora dos limites, interrompe o loop\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 64\u001b[0m, in \u001b[0;36mREPORTEXPLANATION\u001b[1;34m(Xpl, classe, w1, w2)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI-explicação: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXpl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m \u001b[43mEXPLICAR_PI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 77\u001b[0m, in \u001b[0;36mEXPLICAR_PI\u001b[1;34m(Xpl, w1, w2, df)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m      - Valor Mínimo para Sepal Length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal length (cm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m      - Valor Mínimo para Petal Width: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpetal width (cm)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'petal width (cm)'"
     ]
    }
   ],
   "source": [
    "# Cria uma lista para armazenar os valores de delta\n",
    "delta = []\n",
    "\n",
    "# Percorre cada feature selecionada\n",
    "for feature in df.columns[:-1]:  # Exclui a coluna 'target'\n",
    "    # Calcula a diferença entre o valor máximo e o valor mínimo da feature\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# Define o limite de explicação (threshold)\n",
    "threshold = 0  # Use 0 como threshold\n",
    "\n",
    "# Cria uma lista com os valores de features para cada instância\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row))  # Excluir a coluna target\n",
    "\n",
    "# Chama a função para enumerar todas as PI-explicações\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# Imprime o DataFrame\n",
    "print(pi_explicacoes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n",
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "   Classe      PI-Explicação\n",
      "0       0  {(1, [4.9, 0.2])}\n",
      "1       0  {(1, [4.9, 0.2])}\n",
      "2       1  {(1, [4.9, 0.2])}\n",
      "3       1  {(1, [4.9, 0.2])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Seleciona apenas duas features (sepal length e petal width)\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']]\n",
    "\n",
    "# Filtra as classes Iris setosa e Iris versicolor\n",
    "df = df[df['target'].isin([0, 1])]  # Classes 0 e 1\n",
    "\n",
    "# Define as features reais (índices das colunas)\n",
    "R = [0, 1] \n",
    "\n",
    "# Separa os dados em features (X) e classes (y)\n",
    "X = df.iloc[:, R]  # Seleciona as features reais\n",
    "y = df['target']\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cria o modelo de regressão logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Imprime os pesos encontrados\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "\n",
    "# Avalia o modelo com os dados de teste\n",
    "score = modelo.score(X_test, y_test)\n",
    "print(f\"Acurácia: {score:.2f}\")\n",
    "\n",
    "# Define os pesos do classificador linear\n",
    "w1 = modelo.coef_[0][0]  # Peso para 'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso para 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante\n",
    "\n",
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        REPORTEXPLANATION(Xpl, classe, w1, w2)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # Conjunto de literais da explicação\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        while Idx >= 0 and Idx < len(delta):  # Adiciona a condição para verificar o limite de Idx\n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            # Verifica se a PI-explicação já foi encontrada para essa classe\n",
    "            if len(pi_explicacoes) > 1 and pi_explicacoes[-1] == pi_explicacoes[-2]:\n",
    "                break  # Se a PI-explicação for repetida, interrompe o loop\n",
    "    return pi_explicacoes\n",
    "\n",
    "def REPORTEXPLANATION(Xpl, classe, w1, w2):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    EXPLICAR_PI(Xpl, w1, w2)\n",
    "\n",
    "def EXPLICAR_PI(Xpl, w1, w2):\n",
    "    \"\"\"Explica os elementos da PI-explicação.\"\"\"\n",
    "    for item in Xpl:\n",
    "        idx, valores = eval(item)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "        else:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "        if idx == 0:\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "\n",
    "# Cria uma lista para armazenar os valores de delta\n",
    "delta = []\n",
    "\n",
    "# Percorre cada feature selecionada\n",
    "for feature in df.columns[:-1]:  # Exclui a coluna 'target'\n",
    "    # Calcula a diferença entre o valor máximo e o valor mínimo da feature\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# Define o limite de explicação (threshold)\n",
    "threshold = 0  # Use 0 como threshold\n",
    "\n",
    "# Cria uma lista com os valores de features para cada instância\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # Excluir a coluna target\n",
    "\n",
    "# Chama a função para enumerar todas as PI-explicações\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# Imprime o DataFrame\n",
    "print(pi_explicacoes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n",
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "  - Sepal Length (1.3751591278961899): 4.9 cm\n",
      "      - Valor Mínimo para Sepal Length: 4.3 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "  - Sepal Length (1.3751591278961899): 4.9 cm\n",
      "      - Valor Mínimo para Sepal Length: 4.3 cm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Seleciona apenas duas features (sepal length e petal width)\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']]\n",
    "\n",
    "# Filtra as classes Iris setosa e Iris versicolor\n",
    "df = df[df['target'].isin([0, 1])]  # Classes 0 e 1\n",
    "\n",
    "# Define as features reais (índices das colunas)\n",
    "R = [0, 1] \n",
    "\n",
    "# Separa os dados em features (X) e classes (y)\n",
    "X = df.iloc[:, R]\n",
    "y = df['target']\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cria o modelo de regressão logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Imprime os pesos encontrados\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "\n",
    "# Avalia o modelo com os dados de teste\n",
    "score = modelo.score(X_test, y_test)\n",
    "print(f\"Acurácia: {score:.2f}\")\n",
    "\n",
    "# Define os pesos do classificador linear\n",
    "w1 = modelo.coef_[0][0]  # Peso para 'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso para 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante\n",
    "\n",
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        REPORTEXPLANATION(Xpl, classe, w1, w2)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # Conjunto de literais da explicação\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        while Idx >= 0 and Idx < len(delta):  # Adiciona a condição para verificar o limite de Idx\n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            # Se a PI-explicação for repetida, interrompe o loop\n",
    "            if len(pi_explicacoes) > 1 and pi_explicacoes[-1] == pi_explicacoes[-2]:\n",
    "                break\n",
    "    return pi_explicacoes\n",
    "\n",
    "def REPORTEXPLANATION(Xpl, classe, w1, w2):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    EXPLICAR_PI(Xpl, w1, w2, df)\n",
    "\n",
    "def EXPLICAR_PI(Xpl, w1, w2, df):\n",
    "    \"\"\"Explica os elementos da PI-explicação.\"\"\"\n",
    "    for item in Xpl:\n",
    "        idx, valores = eval(item)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "\n",
    "        # Imprime os dados da outra feature (mesmo que ela não esteja na PI-explicação)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "\n",
    "# Cria uma lista para armazenar os valores de delta\n",
    "delta = []\n",
    "\n",
    "# Percorre cada feature selecionada\n",
    "for feature in df.columns[:-1]:  # Exclui a coluna 'target'\n",
    "    # Calcula a diferença entre o valor máximo e o valor mínimo da feature\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# Define o limite de explicação (threshold)\n",
    "threshold = 0  # Use 0 como threshold\n",
    "\n",
    "# Cria uma lista com os valores de features para cada instância\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # Excluir a coluna 'target'\n",
    "\n",
    "# Chama a função para enumerar todas as PI-explicações\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# Ordena o DataFrame pelo índice da instância\n",
    "pi_explicacoes_df = pi_explicacoes_df.sort_values('Classe')\n",
    "\n",
    "# Imprime o DataFrame\n",
    "#print(pi_explicacoes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Seleciona apenas duas features (sepal length e petal width)\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']]\n",
    "\n",
    "# Filtra as classes Iris setosa e Iris versicolor\n",
    "df = df[df['target'].isin([0, 1])]  # Classes 0 e 1\n",
    "\n",
    "# Define as features reais (índices das colunas)\n",
    "R = [0, 1] \n",
    "\n",
    "# Separa os dados em features (X) dados Reais e classes (y) 0 e 1\n",
    "X = df.iloc[:, R]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  petal width (cm)\n",
      "0                 5.1               0.2\n",
      "1                 4.9               0.2\n",
      "2                 4.7               0.2\n",
      "3                 4.6               0.2\n",
      "4                 5.0               0.2\n",
      "..                ...               ...\n",
      "95                5.7               1.2\n",
      "96                5.7               1.3\n",
      "97                6.2               1.3\n",
      "98                5.1               1.1\n",
      "99                5.7               1.3\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Name: target, Length: 100, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
