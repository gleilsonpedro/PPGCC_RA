{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n",
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "  - Sepal Length (1.3751591278961899): 4.9 cm\n",
      "      - Valor Mínimo para Sepal Length: 4.3 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Petal Width (3.505071575134545): 0.2 cm\n",
      "      - Valor Mínimo para Petal Width: 0.1 cm\n",
      "  - Sepal Length (1.3751591278961899): 4.9 cm\n",
      "      - Valor Mínimo para Sepal Length: 4.3 cm\n",
      "   Classe      PI-Explicação\n",
      "0       0  {(1, [4.9, 0.2])}\n",
      "1       1  {(1, [4.9, 0.2])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Seleciona apenas duas features (sepal length e petal width)\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']]\n",
    "\n",
    "# Filtra as classes Iris setosa e Iris versicolor\n",
    "df = df[df['target'].isin([0, 1])]  # Classes 0 e 1\n",
    "\n",
    "# Define as features reais (índices das colunas)\n",
    "R = [0, 1] \n",
    "\n",
    "# Separa os dados em features (X) e classes (y)\n",
    "X = df.iloc[:, R]  # Seleciona as features reais\n",
    "y = df['target']\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cria o modelo de regressão logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Imprime os pesos encontrados\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "\n",
    "# Avalia o modelo com os dados de teste\n",
    "score = modelo.score(X_test, y_test)\n",
    "print(f\"Acurácia: {score:.2f}\")\n",
    "\n",
    "# Define os pesos do classificador linear\n",
    "w1 = modelo.coef_[0][0]  # Peso para 'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso para 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante\n",
    "\n",
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        REPORTEXPLANATION(Xpl, classe, w1, w2)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # Conjunto de literais da explicação\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        # Adiciona a condição para verificar o limite de Idx\n",
    "        while Idx >= 0 and Idx < len(delta): \n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            # Adiciona a PI-explicação à lista, apenas se não existir na lista\n",
    "            if (classe, Xpl) not in pi_explicacoes:\n",
    "                pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            # Verifica se a PI-explicação já foi encontrada para essa classe, interrompe o loop para a classe atual\n",
    "            if len(pi_explicacoes) > 1 and pi_explicacoes[-1] == pi_explicacoes[-2]:\n",
    "                break\n",
    "            Idx += 1 # Incrementa Idx após a chamada da função ONEEXPLANATION\n",
    "    return pi_explicacoes\n",
    "\n",
    "def REPORTEXPLANATION(Xpl, classe, w1, w2):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    EXPLICAR_PI(Xpl, w1, w2, df)\n",
    "\n",
    "def EXPLICAR_PI(Xpl, w1, w2, df):\n",
    "    \"\"\"Explica os elementos da PI-explicação.\"\"\"\n",
    "    for item in Xpl:\n",
    "        idx, valores = eval(item)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "\n",
    "        # Imprime os dados da outra feature (mesmo que ela não esteja na PI-explicação)\n",
    "        if idx == 0:\n",
    "            print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "        else:\n",
    "            print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "            print(f\"      - Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "\n",
    "\n",
    "\n",
    "# Cria uma lista para armazenar os valores de delta\n",
    "delta = []\n",
    "\n",
    "# Percorre cada feature selecionada\n",
    "for feature in df.columns[:-1]:  # Exclui a coluna 'target'\n",
    "    # Calcula a diferença entre o valor máximo e o valor mínimo da feature\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# Define o limite de explicação (threshold)\n",
    "threshold = 0  # Use 0 como threshold\n",
    "\n",
    "# Cria uma lista com os valores de features para cada instância\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # Excluir a coluna 'target'\n",
    "\n",
    "# Chama a função para enumerar todas as PI-explicações\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# Imprime o DataFrame\n",
    "print(pi_explicacoes_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
