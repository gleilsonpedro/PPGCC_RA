{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target #rotulos\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']] # 3 colunas\n",
    "df = df[df['target'].isin([0, 1])] # seleciona calsses setosa e versicolor\n",
    "# separando as clounas classes 0 e 1 e features\n",
    "R = [0, 1] \n",
    "X = df.iloc[:, R]  \n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "score = modelo.score(X_test, y_test)\n",
    "\n",
    "w1 = modelo.coef_[0][0]  # Peso'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante gerado pela reg. logistica\n",
    "\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "print(f\"Acurácia: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (peso - 1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (peso - 3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (peso - 1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (peso - 3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n"
     ]
    }
   ],
   "source": [
    "########## FUNÇÕES ##########\n",
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        EXPLICAR_PI(Xpl, classe, w1, w2, df)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # cria um set vazio para ramazenar os literais da pi-explica\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        \n",
    "        while Idx >= 0 and Idx < len(delta): \n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            # Adiciona a PI-explicação à lista, apenas se não existir na lista\n",
    "            if (classe, Xpl) not in pi_explicacoes:\n",
    "                pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            Idx += 1 # Incrementa Idx após a chamada da função ONEEXPLANATION\n",
    "    return pi_explicacoes\n",
    "# print(pi_explicacoes)\n",
    "# print(delta)\n",
    "def EXPLICAR_PI(Xpl, classe, w1, w2, df):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    for item in Xpl:\n",
    "         idx, valores = eval(item)\n",
    "         if idx == 0:\n",
    "             print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "         else:\n",
    "             print(f\"  - Sepal Length (peso - {w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width (peso - {w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "\n",
    "delta = []\n",
    "for feature in df.columns[:-1]:  # Exclui a ultima coluna 'target'\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# com o(threshold) mais baixo o classificador pode ficar mais rigoroso\n",
    "threshold = 0 \n",
    "\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # adiciona os pares Sepal e petal\n",
    "\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# print(f'\\n{pi_explicacoes_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'petal width (cm)', 'target'], dtype='object')\n",
      "1.7\n",
      "1.8\n",
      "0.1\n",
      "0     0.2\n",
      "1     0.2\n",
      "2     0.2\n",
      "3     0.2\n",
      "4     0.2\n",
      "     ... \n",
      "95    1.2\n",
      "96    1.3\n",
      "97    1.3\n",
      "98    1.1\n",
      "99    1.3\n",
      "Name: petal width (cm), Length: 100, dtype: float64\n",
      "[2.7, 1.7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  petal width (cm)  target\n",
       "0                 5.1               0.2       0\n",
       "1                 4.9               0.2       0\n",
       "2                 4.7               0.2       0\n",
       "3                 4.6               0.2       0\n",
       "4                 5.0               0.2       0\n",
       "..                ...               ...     ...\n",
       "95                5.7               1.2       1\n",
       "96                5.7               1.3       1\n",
       "97                6.2               1.3       1\n",
       "98                5.1               1.1       1\n",
       "99                5.7               1.3       1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = []\n",
    "\n",
    "for feature in df.columns[:-1]:  # Exclui a ultima coluna 'target'\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "\n",
    "print(df.columns)\n",
    "print(delta_feature)\n",
    "print(df[feature].max())\n",
    "print(df[feature].min())\n",
    "print(df[feature])\n",
    "print(delta)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n",
      "\n",
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n",
      "\n",
      "   Classe      PI-Explicação\n",
      "0       0  {(1, [4.9, 0.2])}\n",
      "1       1  {(1, [4.9, 0.2])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target #rotulos\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']] # 3 colunas\n",
    "df = df[df['target'].isin([0, 1])] # seleciona calsses setosa e versicolor\n",
    "# separando as clounas classes 0 e 1 e features\n",
    "R = [0, 1] \n",
    "X = df.iloc[:, R]  \n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "score = modelo.score(X_test, y_test)\n",
    "\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "print(f\"Acurácia: {score:.2f}\\n\")\n",
    "\n",
    "w1 = modelo.coef_[0][0]  # Peso'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante gerado pela reg. logistica\n",
    "\n",
    "########## FUNÇÕES ##########\n",
    "def ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        REPORTEXPLANATION(Xpl, classe, w1, w2)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # cria um set vazio para ramazenar os literais da pi-explica\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        \n",
    "        while Idx >= 0 and Idx < len(delta): \n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            # Adiciona a PI-explicação à lista, apenas se não existir na lista\n",
    "            if (classe, Xpl) not in pi_explicacoes:\n",
    "                pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            Idx += 1 # Incrementa Idx após a chamada da função ONEEXPLANATION\n",
    "    return pi_explicacoes\n",
    "\n",
    "def REPORTEXPLANATION(Xpl, classe, w1, w2):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    EXPLICAR_PI(Xpl, w1, w2)\n",
    "\n",
    "def EXPLICAR_PI(Xpl, w1, w2):\n",
    "    \"\"\"Explica os elementos da PI-explicação.\"\"\"\n",
    "    for item in Xpl:\n",
    "         idx, valores = eval(item)\n",
    "         if idx == 0:\n",
    "             print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "         else:\n",
    "             print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "       \n",
    "\n",
    "delta = []\n",
    "for feature in df.columns[:-1]:  # Exclui a ultima coluna 'target'\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# com o(threshold) mais baixo o classificador pode ficar mais rigoroso\n",
    "threshold = 0 \n",
    "\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # adiciona os pares Sepal e petal\n",
    "\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "print(f'\\n{pi_explicacoes_df}')\n",
    "\n",
    "# --- Função para calcular o slack (Φ) ---\n",
    "def calcular_slack(a, d, w, wo): # o slack é a folga ou tolerância que existe na decisão do classificador.\n",
    "    \"\"\"\n",
    "    Calcula o slack para uma instância.\n",
    "\n",
    "    Args:\n",
    "        a: Valores da instância.\n",
    "        d: Valores mínimos das features.\n",
    "        w: Pesos do classificador.\n",
    "        wo: Termo constante do classificador.\n",
    "\n",
    "    Returns:\n",
    "        O slack (Φ) para a instância.\n",
    "    \"\"\"\n",
    "    return - (wo + sum(w[i] * (a[i] - d[i]) for i in range(len(a))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
