{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[1.37515913 3.50507158]]\n",
      "Intercepto: [-9.9889242]\n",
      "Acurácia: 1.00\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target #rotulos\n",
    "df = df[['sepal length (cm)', 'petal width (cm)', 'target']] # 3 colunas\n",
    "df = df[df['target'].isin([0, 1])] # seleciona calsses setosa e versicolor\n",
    "# separando as clounas classes 0 e 1 e features\n",
    "R = [0, 1] \n",
    "X = df.iloc[:, R]  \n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "score = modelo.score(X_test, y_test)\n",
    "\n",
    "w1 = modelo.coef_[0][0]  # Peso'sepal length'\n",
    "w2 = modelo.coef_[0][1]  # Peso 'petal width'\n",
    "wo = modelo.intercept_[0]  # Termo constante gerado pela reg. logistica\n",
    "\n",
    "print(f\"Pesos: {modelo.coef_}\")\n",
    "print(f\"Intercepto: {modelo.intercept_}\")\n",
    "print(f\"Acurácia: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ONEEXPLANATION() missing 4 required positional arguments: 'Vs', 'delta', 'R', and 'classe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;66;03m# Se o índice da feature estiver fora dos limites, interrompe o loop\u001b[39;00m\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m R, idx\n\u001b[1;32m---> 27\u001b[0m \u001b[43mONEEXPLANATION\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: ONEEXPLANATION() missing 4 required positional arguments: 'Vs', 'delta', 'R', and 'classe'"
     ]
    }
   ],
   "source": [
    "def ONEEXPLANATION(Vs, delta, R, classe):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice da feature (Idx).\n",
    "    \"\"\"\n",
    "    idx = 0  # Inicializa o índice da feature\n",
    "    while R >= 0:\n",
    "        # Verifica se o índice da feature está dentro dos limites da lista delta\n",
    "        if idx + 1 < len(delta):\n",
    "            # Incrementa o índice da feature\n",
    "            idx += 1\n",
    "            # Atualiza o limite de explicação (R)\n",
    "            R -= delta[idx]\n",
    "            # Retorna o limite de explicação atualizado (R) e o índice da feature (idx)\n",
    "            return R, idx\n",
    "        else:\n",
    "            # Se o índice da feature estiver fora dos limites, interrompe o loop\n",
    "            return R, idx\n",
    "        \n",
    "delta = []\n",
    "for i, valor_instancia in enumerate(a):\n",
    "    if w[i] < 0:\n",
    "        delta_feature = (valor_instancia - df[df.columns[i]].max()) * w[i]\n",
    "    else:\n",
    "        delta_feature = (valor_instancia - df[df.columns[i]].min()) * w[i]\n",
    "    delta.append(delta_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1, 0.2], [4.9, 0.2], [4.7, 0.2], [4.6, 0.2], [5.0, 0.2], [5.4, 0.4], [4.6, 0.3], [5.0, 0.2], [4.4, 0.2], [4.9, 0.1], [5.4, 0.2], [4.8, 0.2], [4.8, 0.1], [4.3, 0.1], [5.8, 0.2], [5.7, 0.4], [5.4, 0.4], [5.1, 0.3], [5.7, 0.3], [5.1, 0.3], [5.4, 0.2], [5.1, 0.4], [4.6, 0.2], [5.1, 0.5], [4.8, 0.2], [5.0, 0.2], [5.0, 0.4], [5.2, 0.2], [5.2, 0.2], [4.7, 0.2], [4.8, 0.2], [5.4, 0.4], [5.2, 0.1], [5.5, 0.2], [4.9, 0.2], [5.0, 0.2], [5.5, 0.2], [4.9, 0.1], [4.4, 0.2], [5.1, 0.2], [5.0, 0.3], [4.5, 0.3], [4.4, 0.2], [5.0, 0.6], [5.1, 0.4], [4.8, 0.3], [5.1, 0.2], [4.6, 0.2], [5.3, 0.2], [5.0, 0.2], [7.0, 1.4], [6.4, 1.5], [6.9, 1.5], [5.5, 1.3], [6.5, 1.5], [5.7, 1.3], [6.3, 1.6], [4.9, 1.0], [6.6, 1.3], [5.2, 1.4], [5.0, 1.0], [5.9, 1.5], [6.0, 1.0], [6.1, 1.4], [5.6, 1.3], [6.7, 1.4], [5.6, 1.5], [5.8, 1.0], [6.2, 1.5], [5.6, 1.1], [5.9, 1.8], [6.1, 1.3], [6.3, 1.5], [6.1, 1.2], [6.4, 1.3], [6.6, 1.4], [6.8, 1.4], [6.7, 1.7], [6.0, 1.5], [5.7, 1.0], [5.5, 1.1], [5.5, 1.0], [5.8, 1.2], [6.0, 1.6], [5.4, 1.5], [6.0, 1.6], [6.7, 1.5], [6.3, 1.3], [5.6, 1.3], [5.5, 1.3], [5.5, 1.2], [6.1, 1.4], [5.8, 1.2], [5.0, 1.0], [5.6, 1.3], [5.7, 1.2], [5.7, 1.3], [6.2, 1.3], [5.1, 1.1], [5.7, 1.3]]\n",
      "Classe: 0\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (peso - 1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (peso - 3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n",
      "Classe: 1\n",
      "PI-explicação: {'(1, [4.9, 0.2])'}\n",
      "  - Sepal Length (peso - 1.3751591278961863): 4.9 cm\n",
      "    Valor Mínimo para Sepal Length: 4.3 cm\n",
      "  - Petal Width (peso - 3.505071575134543): 0.2 cm\n",
      "    Valor Mínimo para Petal Width: 0.1 cm\n"
     ]
    }
   ],
   "source": [
    "########## FUNÇÕES ##########\n",
    "def ONEEXPLANATION(Vs, delta, R):\n",
    "    \"\"\"\n",
    "    Encontrar uma PI-explicação usando um algoritmo guloso.\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        R: Limite de explicação.\n",
    "        Idx: Índice atual na lista delta.\n",
    "        Xpl: Conjunto de literais da explicação.\n",
    "        classe: Classe atual sendo considerada.\n",
    "    Returns:\n",
    "        Tupla com o limite atualizado (R) e o índice atualizado (Idx).\n",
    "    \"\"\"\n",
    "    Idx = -1\n",
    "    Xpl = []\n",
    "    # Verifica se Idx está dentro dos limites da lista antes de incrementá-lo\n",
    "    if Idx + 1 < len(delta):\n",
    "        # Se o peso da primeira feature for maior\n",
    "        if abs(w1) > abs(w2):\n",
    "            Idx = 0 # Escolhe a primeira feature como a mais importante\n",
    "        else:\n",
    "            Idx = 1 # Escolhe a segunda feature como a mais importante\n",
    "\n",
    "        R -= delta[Idx]\n",
    "        # Converte a tupla para string para que seja \"hashable\"\n",
    "        Xpl.add(str((Idx, Vs[Idx])))  # Adiciona o literal à PI-explicação\n",
    "        EXPLICAR_PI(Xpl, classe, w1, w2, df)  # Imprime ou processa a PI-explicação atual\n",
    "        return R, Idx\n",
    "    else:\n",
    "        # Se Idx estiver fora dos limites, interrompe o loop\n",
    "        return R, Idx\n",
    "\n",
    "## def ALLEXPLANATIONS(Vs, delta, threshold, w1, w2):\n",
    "    \"\"\"\n",
    "    Enumerar todas as PI-explicações usando backtracking, considerando todas as classes.\n",
    "\n",
    "    Args:\n",
    "        Vs: Valores da instância.\n",
    "        delta: Lista ordenada de valores de delta.\n",
    "        threshold: Limite de explicação.\n",
    "        w1: Peso para a primeira feature.\n",
    "        w2: Peso para a segunda feature.\n",
    "\n",
    "    Returns:\n",
    "        Lista de tuplas com a classe e a PI-explicação para cada instância.\n",
    "    \"\"\"\n",
    "    pi_explicacoes = []  # Lista para armazenar as PI-explicações\n",
    "    for classe in range(2):  # Itera sobre as duas classes (0 e 1)\n",
    "        Xpl = set()  # cria um set vazio para ramazenar os literais da pi-explica\n",
    "        Idx = 0\n",
    "        R = 0\n",
    "        \n",
    "        while Idx >= 0 and Idx < len(delta): \n",
    "            R, Idx = ONEEXPLANATION(Vs, delta, R, Idx, Xpl, classe)\n",
    "            # Ajuste para garantir que R não se torne negativo\n",
    "            if R < 0:\n",
    "                R = 0\n",
    "            # Adiciona a PI-explicação à lista, apenas se não existir na lista\n",
    "            if (classe, Xpl) not in pi_explicacoes:\n",
    "                pi_explicacoes.append((classe, Xpl))  # Adiciona a PI-explicação à lista\n",
    "            Idx += 1 # Incrementa Idx após a chamada da função ONEEXPLANATION\n",
    "    return pi_explicacoes\n",
    "# print(pi_explicacoes)\n",
    "# print(delta)\n",
    "def EXPLICAR_PI(Xpl, classe, w1, w2, df):\n",
    "    \"\"\"Imprime a PI-explicação.\"\"\"\n",
    "    print(f\"Classe: {classe}\")\n",
    "    print(f\"PI-explicação: {Xpl}\")\n",
    "    for item in Xpl:\n",
    "         idx, valores = eval(item)\n",
    "         if idx == 0:\n",
    "             print(f\"  - Sepal Length ({w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width ({w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "         else:\n",
    "             print(f\"  - Sepal Length (peso - {w1}): {valores[0]} cm\")\n",
    "             print(f\"    Valor Mínimo para Sepal Length: {df['sepal length (cm)'].min()} cm\")\n",
    "             print(f\"  - Petal Width (peso - {w2}): {valores[1]} cm\")\n",
    "             print(f\"    Valor Mínimo para Petal Width: {df['petal width (cm)'].min()} cm\")\n",
    "\n",
    "####### delta_feature = (valor_instancia - df[feature].max()) * w_feature, se #w_feature < 0\n",
    "#     delta_feature = (valor_instancia - df[feature].min()) * w_feature, se #w_feature > 0\n",
    "#assumindo predicao para a classe +1\n",
    "\n",
    "'''delta_feature = (valor_instancia - df[feature].max()) * w_feature, se w_feature < 0\n",
    "     delta_feature = (valor_instancia - df[feature].min()) * w_feature, se w_feature > 0\n",
    "assumindo predicao para a classe +1'''\n",
    "delta = []\n",
    "for feature in df.columns[:-1]:  # Exclui a ultima coluna 'target'\n",
    "    delta_feature = df[feature].max() - df[feature].min()\n",
    "    delta.append(delta_feature)\n",
    "\n",
    "# ordenar a saida do delta \"sem perder os valores das features que eles se referem\"\n",
    "\n",
    "# com o(threshold) mais baixo o classificador pode ficar mais rigoroso\n",
    "threshold = 0 \n",
    "\n",
    "Vs = []\n",
    "for index, row in df.iterrows():\n",
    "    Vs.append(list(row[:-1]))  # adiciona os pares Sepal e petal\n",
    "\n",
    "print(Vs)\n",
    "\n",
    "pi_explicacoes = ALLEXPLANATIONS(Vs, delta, threshold, w1, w2)\n",
    "\n",
    "# Cria um DataFrame com as PI-explicações\n",
    "pi_explicacoes_df = pd.DataFrame(pi_explicacoes, columns=['Classe', 'PI-Explicação'])\n",
    "\n",
    "# print(f'\\n{pi_explicacoes_df}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
