{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras por classe após filtragem:\n",
      "Classe 0: 6903\n",
      "Classe 1: 7877\n",
      "Classes treinadas pelo modelo: [0 1]\n",
      "Dimensões dos coeficientes do modelo: (1, 784)\n",
      "Dimensões dos interceptos do modelo: (1,)\n",
      "Classe prevista pelo modelo para a instância: 0\n",
      "No solution found\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from z3 import *\n",
    "\n",
    "# Carregando o dataset MNIST e selecionando apenas as classes 0 e 1\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(np.int8)\n",
    "\n",
    "# Selecionar apenas as classes 0 e 1\n",
    "mask = (y == 0) | (y == 1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Verificando o número de amostras por classe\n",
    "print(\"Número de amostras por classe após filtragem:\")\n",
    "print(\"Classe 0:\", np.sum(y == 0))\n",
    "print(\"Classe 1:\", np.sum(y == 1))\n",
    "\n",
    "# Reduzir para as primeiras 500 amostras de cada classe (se possível)\n",
    "num_samples = 500\n",
    "X_class_0 = X[y == 0].iloc[:num_samples].to_numpy()\n",
    "y_class_0 = y[y == 0].iloc[:num_samples].to_numpy()\n",
    "X_class_1 = X[y == 1].iloc[:num_samples].to_numpy()\n",
    "y_class_1 = y[y == 1].iloc[:num_samples].to_numpy()\n",
    "\n",
    "X = np.vstack((X_class_0, X_class_1))\n",
    "y = np.hstack((y_class_0, y_class_1))\n",
    "feature_names = [f'pixel_{i}' for i in range(X.shape[1])]  # Nomes das características (pixels)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Treinando o modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Verificando classes treinadas\n",
    "print(\"Classes treinadas pelo modelo:\", model.classes_)\n",
    "\n",
    "# Verificando as dimensões dos coeficientes e interceptos\n",
    "print(\"Dimensões dos coeficientes do modelo:\", model.coef_.shape)\n",
    "print(\"Dimensões dos interceptos do modelo:\", model.intercept_.shape)\n",
    "\n",
    "# Função para criar uma explicação minimal usando Z3 Solver\n",
    "def minimal_explanation(model, instance, target_class, epsilon=1e-6, timeout=60000):\n",
    "    num_features = instance.shape[0]\n",
    "    weights = model.coef_[0]\n",
    "    intercept = model.intercept_[0]\n",
    "    \n",
    "    # Z3 Optimize\n",
    "    opt = Optimize()\n",
    "    opt.set(\"timeout\", timeout)  # Adiciona limite de tempo (em milissegundos)\n",
    "    \n",
    "    # Variáveis Z3\n",
    "    feature_selection = [Bool(f'f{i}') for i in range(num_features)]\n",
    "    \n",
    "    # Função de decisão do modelo\n",
    "    def decision_function(weights, intercept, instance, selected_features):\n",
    "        return Sum([If(selected_features[i], instance[i] * weights[i], 0) for i in range(num_features)]) + intercept\n",
    "    \n",
    "    # Adicionar restrições ao solver\n",
    "    decision_target = decision_function(weights, intercept, instance, feature_selection)\n",
    "    decision_other = -decision_function(weights, -intercept, instance, feature_selection)\n",
    "    constraint = decision_target > decision_other + epsilon\n",
    "    opt.add(constraint)\n",
    "    \n",
    "    # Minimizar o número de características selecionadas\n",
    "    opt.minimize(Sum([If(f, 1, 0) for f in feature_selection]))\n",
    "\n",
    "    # Check satisfiability and get the model if possible\n",
    "    result = opt.check()\n",
    "    \n",
    "    if result == sat:\n",
    "        m = opt.model()\n",
    "        explanation = [i for i in range(num_features) if m.evaluate(feature_selection[i])]\n",
    "        explanation_features = [feature_names[i] for i in explanation]  # Nomes das características\n",
    "        return result, explanation, explanation_features\n",
    "    else:\n",
    "        return result, None, None\n",
    "\n",
    "# Exemplo de uso\n",
    "instance = X[0]  # Exemplo de instância para explicar\n",
    "target_class = model.predict([instance])[0]  # Classe prevista pelo modelo\n",
    "\n",
    "print(\"Classe prevista pelo modelo para a instância:\", target_class)\n",
    "\n",
    "result, explanation, explanation_features = minimal_explanation(model, instance, target_class)\n",
    "if explanation:\n",
    "    print(\"Objective: Minimize selected features\")\n",
    "    print(\"Solver result:\", result)\n",
    "    print(\"Model found. Explanation (indices):\", explanation)\n",
    "    print(\"Explicação minimal (nomes das características):\", explanation_features)\n",
    "else:\n",
    "    print(\"No solution found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes treinadas pelo modelo: [2 4 7]\n",
      "Dimensões dos coeficientes do modelo: (3, 50)\n",
      "Dimensões dos interceptos do modelo: (3,)\n",
      "Classe prevista pelo modelo para a instância: 4\n",
      "Objective: Minimize selected features\n",
      "Solver result: sat\n",
      "Model found. Explanation (indices): [27, 46]\n",
      "Explicação minimal (nomes das características): ['pixel_27', 'pixel_46']\n"
     ]
    }
   ],
   "source": [
    "# MELHOR FUNCIONAL COM VÁRIAS OMODIFICAÇOES E SIMPLIFICAÇÕES NOS DADOS E NA REGRESSÃO LOGÍSTICA\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from z3 import *\n",
    "\n",
    "# 1. Carregando o dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data  # Matriz com os dados de pixels das imagens\n",
    "y = mnist.target.astype(np.int8)  # Vetor com as labels (classes) das imagens\n",
    "\n",
    "# 2. Selecionando apenas as classes 2, 4 e 7\n",
    "mask = (y == 2) | (y == 4) | (y == 7)  # Criando uma máscara booleana para selecionar as classes desejadas\n",
    "X = X[mask]  # Filtrando os dados para manter apenas as amostras das classes 2, 4 e 7\n",
    "y = y[mask]  # Filtrando as labels para manter apenas as labels das classes 2, 4 e 7\n",
    "\n",
    "# 3. Seleção de Pixels\n",
    "k_features = 50  # Número de recursos (pixels) a serem selecionados\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features)  # Criando um objeto SelectKBest usando a informação dos pixels para selecionar recursos\n",
    "X_selected = selector.fit_transform(X, y)  # Aplicando a seleção de recursos para selecionar os melhores k_features pixels\n",
    "feature_names = [f'pixel_{i}' for i in range(X_selected.shape[1])]  # Criando nomes para os pixels selecionados\n",
    "\n",
    "# 4. Normalizando os dados\n",
    "scaler = StandardScaler()  # Criando um objeto StandardScaler para normalizar os dados\n",
    "X_selected = scaler.fit_transform(X_selected)  # Normalizando os dados selecionados\n",
    "\n",
    "# 5. Treinando o modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)  # Criando um modelo de regressão logística\n",
    "model.fit(X_selected, y)  # Treinando o modelo com os dados selecionados e normalizados\n",
    "\n",
    "# 6. Verificando as classes treinadas\n",
    "print(\"Classes treinadas pelo modelo:\", model.classes_)\n",
    "\n",
    "# 7. Verificando as dimensões dos coeficientes e interceptos\n",
    "print(\"Dimensões dos coeficientes (pesos) do modelo:\", model.coef_.shape)\n",
    "print(\"Dimensões dos interceptos (viés) do modelo:\", model.intercept_.shape)\n",
    "# Dimensões dos coeficientes o primeiro numero é a quantidade de classes \n",
    "# Segundo número é a quantidade de pixels do MNIST para usar no modelo\n",
    "# O vetor de interceptos possui um valor para cada classe, que representa \n",
    "# O valor da função de decisão (probabilidade) quando todas as features são zero.\n",
    "\n",
    "# 8. Função para criar uma explicação minimal usando Z3 Solver\n",
    "def minimal_explanation(model, instance, target_class, epsilon=0.2, timeout=60000):\n",
    "    num_features = instance.shape[0]  # Número de recursos na instância (pixels selecionados)\n",
    "    weights = model.coef_  # Pesos do modelo (coeficientes)\n",
    "    intercepts = model.intercept_  # Interceptos do modelo\n",
    "    \n",
    "    # Z3 Optimize\n",
    "    opt = Optimize()  # Criando um objeto Optimize para o Z3 Solver\n",
    "    opt.set(\"timeout\", timeout)  # Definindo um limite de tempo para o solver (60000 milissegundos = 1 minuto) para não demorar muito\n",
    "    \n",
    "    # Variáveis Z3 (representando a seleção de recursos)\n",
    "    feature_selection = [Bool(f'f{i}') for i in range(num_features)]  # Criando variáveis booleanas para cada recurso (pixel)\n",
    "\n",
    "    # Função de decisão do modelo (usada para definir as restrições do Z3)\n",
    "    def decision_function(weights, intercept, instance, selected_features):\n",
    "        return Sum([If(selected_features[i], instance[i] * weights[i], 0) for i in range(num_features)]) + intercept\n",
    "\n",
    "    # Obter o índice da classe alvo\n",
    "    target_index = np.where(model.classes_ == target_class)[0][0]  # Encontrando o índice da classe alvo\n",
    "\n",
    "    # Adicionar restrições ao solver\n",
    "    for i in range(len(model.classes_)):\n",
    "        if i != target_index:  # Para cada classe diferente da classe alvo\n",
    "            decision_target = decision_function(weights[target_index], intercepts[target_index], instance, feature_selection)  # Calculando a função de decisão para a classe alvo\n",
    "            decision_other = decision_function(weights[i], intercepts[i], instance, feature_selection)  # Calculando a função de decisão para outra classe\n",
    "            \n",
    "            # Relaxamento das Restrições: Ajuste da folga (epsilon)\n",
    "            constraint = decision_target > decision_other + epsilon  # Definindo a restrição para a função de decisão da classe alvo ser maior que a função de decisão das outras classes com uma margem (epsilon)\n",
    "            opt.add(constraint)  # Adicionando a restrição ao solver\n",
    "\n",
    "    # Minimizar o número de características selecionadas\n",
    "    opt.minimize(Sum([If(f, 1, 0) for f in feature_selection]))  # Definindo a função de otimização para minimizar o número de recursos selecionados\n",
    "\n",
    "    # Check satisfiability and get the model if possible\n",
    "    result = opt.check()  # Verificando se o Z3 Solver encontrou uma solução satisfazendo as restrições\n",
    "\n",
    "    if result == sat:  # Se o solver encontrou uma solução\n",
    "        m = opt.model()  # Obtendo o modelo (interpretação) do solver\n",
    "        explanation = [i for i in range(num_features) if m.evaluate(feature_selection[i])]  # Identificando os recursos (pixels) selecionados na explicação minimal\n",
    "        explanation_features = [feature_names[i] for i in explanation]  # Obtendo os nomes dos recursos (pixels) selecionados\n",
    "        return result, explanation, explanation_features  # Retornando o resultado do solver, a lista de índices dos recursos selecionados e os nomes dos recursos selecionados\n",
    "    else:  # Se o solver não encontrou uma solução\n",
    "        return result, None, None  # Retornando None para a explicação\n",
    "\n",
    "# 9. Exemplo de uso\n",
    "instance = X_selected[0]  # Selecionando a primeira instância (imagem) do conjunto de dados\n",
    "target_class = model.predict([instance])[0]  # Obtendo a classe prevista pelo modelo para a instância\n",
    "\n",
    "print(\"Classe prevista pelo modelo para a instância:\", target_class)\n",
    "\n",
    "result, explanation, explanation_features = minimal_explanation(model, instance, target_class)\n",
    "if explanation:\n",
    "    print(\"Objective: Minimize selected features\")\n",
    "    print(\"Solver result:\", result)\n",
    "    print(\"Model found. Explanation (indices):\", explanation)\n",
    "    print(\"Explicação minimal (nomes das características):\", explanation_features)\n",
    "else:\n",
    "    print(\"No solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento do Dataset MNIST: O código começa importando as bibliotecas necessárias, incluindo o fetch_openml para carregar o dataset MNIST. O dataset é dividido em duas partes: X (dados de pixels das imagens) e y (labels das imagens).\n",
    "Seleção das Classes 2, 4 e 7: O código seleciona apenas as amostras das classes 2, 4 e 7 usando uma máscara booleana (mask) e filtra os dados X e as labels y.\n",
    "Seleção de Recursos (Mutual Information): O código usa o SelectKBest para selecionar os melhores 50 pixels (features) com base na informação mútua (mutual_info_classif). Isso significa que ele escolhe os pixels que são mais informativos para a classificação das classes 2, 4 e 7. O resultado é armazenado em X_selected.\n",
    "Normalização dos Dados: O código normaliza os dados selecionados (X_selected) usando o StandardScaler para garantir que todas as features tenham a mesma escala.\n",
    "Treinamento do Modelo de Regressão Logística: O código treina um modelo de regressão logística usando os dados selecionados e normalizados.\n",
    "Verificação das Classes Treinadas: O código exibe as classes que o modelo foi treinado a prever.\n",
    "Verificação das Dimensões dos Coeficientes e Interceptos: O código exibe as dimensões dos coeficientes (pesos) e interceptos do modelo.\n",
    "Função minimal_explanation:\n",
    "Esta função usa o Z3 Solver para encontrar uma explicação minimal para a previsão do modelo.\n",
    "Z3 Optimize: Um objeto Optimize do Z3 é criado para otimizar as restrições do solver.\n",
    "Variáveis Z3: Variáveis booleanas (feature_selection) são criadas para representar a seleção de cada pixel (feature).\n",
    "Função de Decisão: Uma função decision_function é definida para calcular a função de decisão do modelo, que representa a probabilidade de uma imagem pertencer a uma determinada classe.\n",
    "Restrições: As restrições para o Z3 Solver são adicionadas usando a função de decisão. As restrições garantem que a função de decisão para a classe alvo seja maior que a função de decisão para as outras classes, com uma pequena margem (epsilon).\n",
    "Otimização: A função minimize do Z3 é usada para minimizar o número de recursos selecionados, buscando a explicação minimal.\n",
    "Verificação da Solução: O Z3 Solver verifica se existe uma solução satisfatória às restrições. Se houver, ele retorna a explicação minimal, que inclui a lista de índices dos recursos selecionados e seus nomes.\n",
    "Exemplo de Uso:\n",
    "O código seleciona uma instância (imagem) do conjunto de dados e usa o modelo para prever a classe.\n",
    "A função minimal_explanation é chamada para encontrar a explicação minimal para a previsão.\n",
    "Os resultados são impressos na tela, incluindo a explicação minimal.\n",
    "Observações:\n",
    "Ajuste os parâmetros k_features e epsilon para otimizar o desempenho do Z3 Solver.\n",
    "Se você estiver tendo problemas para obter uma explicação minimal, considere tentar outras técnicas de simplificação do modelo, como reduzir ainda mais o número de recursos ou usar técnicas de regularização no modelo de regressão logística.\n",
    "Para problemas complexos, você pode explorar bibliotecas de explicabilidade específicas para aprendizado de máquina, como SHAP e LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes treinadas pelo modelo: [2 4 7]\n",
      "Dimensões dos coeficientes do modelo: (3, 50)\n",
      "Dimensões dos interceptos do modelo: (3,)\n",
      "Classe prevista pelo modelo para a instância: 4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Pintando a imagem com a explicação minimal\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explanation:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# 10. Obter a imagem original (usando X)\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))  \u001b[38;5;66;03m# Pega a imagem original de X\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# 11. Criar uma cópia da imagem para pintar os pixels irrelevantes de vermelho\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     image_with_explanation \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from z3 import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Carregando o dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data  # Matriz com os dados de pixels das imagens\n",
    "y = mnist.target.astype(np.int8)  # Vetor com as labels (classes) das imagens\n",
    "\n",
    "# 2. Selecionando apenas as classes 2, 4 e 7\n",
    "mask = (y == 2) | (y == 4) | (y == 7)  # Criando uma máscara booleana para selecionar as classes desejadas\n",
    "X = X[mask]  # Filtrando os dados para manter apenas as amostras das classes 2, 4 e 7\n",
    "y = y[mask]  # Filtrando as labels para manter apenas as labels das classes 2, 4 e 7\n",
    "\n",
    "# 3. Seleção de Recursos (Mutual Information)\n",
    "k_features = 50  # Número de recursos (pixels) a serem selecionados\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features)  # Criando um objeto SelectKBest usando a informação mútua para selecionar recursos\n",
    "X_selected = selector.fit_transform(X, y)  # Aplicando a seleção de recursos para selecionar os melhores k_features pixels\n",
    "feature_names = [f'pixel_{i}' for i in range(X_selected.shape[1])]  # Criando nomes para os pixels selecionados\n",
    "\n",
    "# 4. Normalizando os dados\n",
    "scaler = StandardScaler()  # Criando um objeto StandardScaler para normalizar os dados\n",
    "X_selected = scaler.fit_transform(X_selected)  # Normalizando os dados selecionados\n",
    "\n",
    "# 5. Treinando o modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)  # Criando um modelo de regressão logística\n",
    "model.fit(X_selected, y)  # Treinando o modelo com os dados selecionados e normalizados\n",
    "\n",
    "# 6. Verificando as classes treinadas\n",
    "print(\"Classes treinadas pelo modelo:\", model.classes_)\n",
    "\n",
    "# 7. Verificando as dimensões dos coeficientes e interceptos\n",
    "print(\"Dimensões dos coeficientes do modelo:\", model.coef_.shape)\n",
    "print(\"Dimensões dos interceptos do modelo:\", model.intercept_.shape)\n",
    "\n",
    "# 8. Função para criar uma explicação minimal usando Z3 Solver\n",
    "def minimal_explanation(model, instance, target_class, epsilon=0.2, timeout=60000):\n",
    "    num_features = instance.shape[0]  # Número de recursos na instância (pixels selecionados)\n",
    "    weights = model.coef_  # Pesos do modelo (coeficientes)\n",
    "    intercepts = model.intercept_  # Interceptos do modelo\n",
    "    \n",
    "    # Z3 Optimize\n",
    "    opt = Optimize()  # Criando um objeto Optimize para o Z3 Solver\n",
    "    opt.set(\"timeout\", timeout)  # Definindo um limite de tempo para o solver (60000 milissegundos = 1 minuto)\n",
    "    \n",
    "    # Variáveis Z3 (representando a seleção de recursos)\n",
    "    feature_selection = [Bool(f'f{i}') for i in range(num_features)]  # Criando variáveis booleanas para cada recurso (pixel)\n",
    "\n",
    "    # Função de decisão do modelo (usada para definir as restrições do Z3)\n",
    "    def decision_function(weights, intercept, instance, selected_features):\n",
    "        return Sum([If(selected_features[i], instance[i] * weights[i], 0) for i in range(num_features)]) + intercept\n",
    "\n",
    "    # Obter o índice da classe alvo\n",
    "    target_index = np.where(model.classes_ == target_class)[0][0]  # Encontrando o índice da classe alvo\n",
    "\n",
    "    # Adicionar restrições ao solver\n",
    "    for i in range(len(model.classes_)):\n",
    "        if i != target_index:  # Para cada classe diferente da classe alvo\n",
    "            decision_target = decision_function(weights[target_index], intercepts[target_index], instance, feature_selection)  # Calculando a função de decisão para a classe alvo\n",
    "            decision_other = decision_function(weights[i], intercepts[i], instance, feature_selection)  # Calculando a função de decisão para outra classe\n",
    "            \n",
    "            # Relaxamento das Restrições: Ajuste da folga (epsilon)\n",
    "            constraint = decision_target > decision_other + epsilon  # Definindo a restrição para a função de decisão da classe alvo ser maior que a função de decisão das outras classes com uma margem (epsilon)\n",
    "            opt.add(constraint)  # Adicionando a restrição ao solver\n",
    "\n",
    "    # Minimizar o número de características selecionadas\n",
    "    opt.minimize(Sum([If(f, 1, 0) for f in feature_selection]))  # Definindo a função de otimização para minimizar o número de recursos selecionados\n",
    "\n",
    "    # Check satisfiability and get the model if possible\n",
    "    result = opt.check()  # Verificando se o Z3 Solver encontrou uma solução satisfazendo as restrições\n",
    "\n",
    "    if result == sat:  # Se o solver encontrou uma solução\n",
    "        m = opt.model()  # Obtendo o modelo (interpretação) do solver\n",
    "        explanation = [i for i in range(num_features) if m.evaluate(feature_selection[i])]  # Identificando os recursos (pixels) selecionados na explicação minimal\n",
    "        explanation_features = [feature_names[i] for i in explanation]  # Obtendo os nomes dos recursos (pixels) selecionados\n",
    "        return result, explanation, explanation_features  # Retornando o resultado do solver, a lista de índices dos recursos selecionados e os nomes dos recursos selecionados\n",
    "    else:  # Se o solver não encontrou uma solução\n",
    "        return result, None, None  # Retornando None para a explicação\n",
    "\n",
    "# 9. Exemplo de uso\n",
    "instance = X_selected[0]  # Selecionando a primeira instância (imagem) do conjunto de dados\n",
    "target_class = model.predict([instance])[0]  # Obtendo a classe prevista pelo modelo para a instância\n",
    "\n",
    "print(\"Classe prevista pelo modelo para a instância:\", target_class)\n",
    "\n",
    "result, explanation, explanation_features = minimal_explanation(model, instance, target_class)\n",
    "\n",
    "# Pintando a imagem com a explicação minimal\n",
    "if explanation:\n",
    "    # 10. Obter a imagem original (usando X)\n",
    "    image = X[0].reshape((28, 28))  # Pega a imagem original de X\n",
    "    \n",
    "    # 11. Criar uma cópia da imagem para pintar os pixels irrelevantes de vermelho\n",
    "    image_with_explanation = image.copy()\n",
    "    \n",
    "    # 12. Transformar os índices da explicação minimal para os pixels originais\n",
    "    explanation_original_indices = selector.inverse_transform(X_selected)[0][explanation]  # Transforma os indices para o X original\n",
    "\n",
    "    # 13. Pintar os pixels irrelevantes de vermelho\n",
    "    for i in range(image_with_explanation.shape[0]):\n",
    "        for j in range(image_with_explanation.shape[1]):\n",
    "            index = i * 28 + j\n",
    "            if index not in explanation_original_indices:  # Use os indices originais\n",
    "                image_with_explanation[i, j] = 255\n",
    "    \n",
    "    # 14. Plotar a imagem com a explicação minimal\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image_with_explanation, cmap='gray')\n",
    "    plt.title(f\"Classe Prevista: {target_class}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Objective: Minimize selected features\")\n",
    "    print(\"Solver result:\", result)\n",
    "    print(\"Model found. Explanation (indices):\", explanation)\n",
    "    print(\"Explicação minimal (nomes das características):\", explanation_features)\n",
    "else:\n",
    "    print(\"No solution found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
