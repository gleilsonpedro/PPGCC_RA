{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento do dataset MNIST:\n",
    "fetch_openml('mnist_784', version=1): Carrega o dataset MNIST da biblioteca fetch_openml, especificando a versão 1 do dataset.\n",
    "X = mnist.data: Armazena os dados de pixels das imagens no DataFrame X.\n",
    "y = mnist.target.astype(np.int8): Armazena as labels (classes) das imagens no vetor y, convertendo-as para inteiros de 8 bits para otimizar o armazenamento.\n",
    "Filtrando as classes:\n",
    "mask = (y == 2) | (y == 4) | (y == 7): Cria uma máscara booleana que seleciona apenas as imagens das classes 2, 4 e 7.\n",
    "X = X[mask]: Filtra o DataFrame X usando a máscara, mantendo apenas as imagens das classes 2, 4 e 7.\n",
    "y = y[mask]: Filtra o vetor de labels y usando a máscara, mantendo apenas as labels correspondentes às imagens em X após o filtro.\n",
    "Seleção de pixels:\n",
    "k_features = 50: Define o número de pixels (recursos) a serem selecionados para o modelo.\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features): Cria um objeto SelectKBest para selecionar os pixels mais informativos, utilizando a métrica mutual_info_classif para medir a informação mútua entre os pixels e a classe.\n",
    "X_selected = selector.fit_transform(X, y): Seleciona os k_features pixels mais informativos e armazena os dados selecionados em X_selected.\n",
    "feature_names = [f'pixel_{i}' for i in range(X_selected.shape[1])]: Cria uma lista com os nomes dos pixels selecionados, usando o formato \"pixel_i\".\n",
    "Normalização dos dados:\n",
    "scaler = StandardScaler(): Cria um objeto StandardScaler para normalizar os dados, que é uma técnica comum para melhorar o desempenho de modelos de machine learning.\n",
    "X_selected = scaler.fit_transform(X_selected): Normaliza os dados selecionados em X_selected para que tenham média zero e desvio padrão 1.\n",
    "Treinando o modelo de regressão logística:\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200): Cria um modelo de regressão logística usando o método \"one-vs-rest\" (multi_class='ovr') e o otimizador \"lbfgs\" (solver='lbfgs'). Define o número máximo de iterações (max_iter) para 200.\n",
    "model.fit(X_selected, y): Treina o modelo de regressão logística usando os dados selecionados e normalizados (X_selected) e as labels (y).\n",
    "Verificando as classes treinadas:\n",
    "print(\"Classes treinadas pelo modelo:\", model.classes_): Imprime as classes que o modelo foi treinado para prever.\n",
    "Verificando as dimensões dos coeficientes e interceptos:\n",
    "print(\"Dimensões dos coeficientes (pesos) do modelo:\", model.coef_.shape): Imprime as dimensões da matriz de coeficientes do modelo.\n",
    "print(\"Dimensões dos interceptos (viés) do modelo:\", model.intercept_.shape): Imprime as dimensões do vetor de interceptos do modelo.\n",
    "Função minimal_explanation:\n",
    "Essa função utiliza o Z3 Solver para encontrar uma explicação minimal para a previsão do modelo, mostrando quais pixels (recursos) são mais importantes para a previsão.\n",
    "Z3 Solver: O Z3 Solver é uma ferramenta de resolução de restrições (SAT) que pode ser utilizada para encontrar soluções para problemas lógicos.\n",
    "Restrições: A função define restrições para garantir que a função de decisão da classe alvo seja maior que a função de decisão de outras classes, com uma margem de epsilon.\n",
    "Minimização: A função de otimização do Z3 Solver é configurada para minimizar o número de recursos selecionados.\n",
    "Explicação minimal: Se o solver encontrar uma solução, ele retorna o resultado, a lista de índices dos recursos selecionados e os nomes dos recursos selecionados.\n",
    "Exemplo de uso:\n",
    "Selecionando uma instância: Um índice de instância é selecionado e a imagem correspondente é extraída do DataFrame X, convertendo-a para um array NumPy.\n",
    "Previsão: A classe prevista pelo modelo para a instância é obtida.\n",
    "Explicação minimal: A função minimal_explanation é chamada para calcular a explicação minimal usando os dados normalizados e a classe prevista.\n",
    "Visualização: Se uma explicação for encontrada, a imagem é plotada, destacando os pixels irrelevantes em vermelho.\n",
    "Em resumo, este código demonstra como usar um modelo de regressão logística para classificar imagens do dataset MNIST, com a técnica de seleção de recursos SelectKBest e uma explicação minimal usando o Z3 Solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from z3 import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Carregando o dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data  # Matriz com os dados de pixels das imagens \n",
    "y = mnist.target.astype(np.int8)  # Vetor com as labels (classes) das imagens, convertendo-as para inteiros de 8 bits\n",
    "\n",
    "\n",
    "# 2. Selecionando apenas as classes 2, 4 e 7\n",
    "mask = (y == 2) | (y == 4) | (y == 7)  # Criando uma máscara booleana para selecionar as classes desejadas\n",
    "X = X[mask]  # Filtrando os dados para manter apenas as imagens das classes 2, 4 e 7\n",
    "y = y[mask]  # Filtrando as labels para manter apenas as labels das classes 2, 4 e 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Seleção de Pixels\n",
    "k_features = 50  # Número de recursos (pixels) a serem selecionados\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features)  # Criando um objeto SelectKBest para selecionar os pixels mais informativos de k_features\n",
    "X_selected = selector.fit_transform(X, y)  # Aplicando a seleção de recursos para selecionar os melhores k_features pixels\n",
    "feature_names = [f'pixel_{i}' for i in range(X_selected.shape[1])]  # Criando nomes para os pixels selecionados\n",
    "\n",
    "# 4. Normalizando os dados\n",
    "scaler = StandardScaler()  # Criando um objeto StandardScaler para normalizar os dados\n",
    "X_selected = scaler.fit_transform(X_selected)  # Normalizando os dados selecionados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42724016 -0.46083979 -0.47796343 ... -0.53999258 -0.61818247\n",
      "  -0.7005951 ]\n",
      " [-0.42724016 -0.46083979 -0.47796343 ...  2.14939723  1.88369717\n",
      "   0.98636552]\n",
      " [-0.42724016 -0.46083979 -0.47796343 ... -0.53999258 -0.61818247\n",
      "  -0.40679859]\n",
      " ...\n",
      " [-0.42724016 -0.46083979 -0.47796343 ... -0.53999258 -0.61818247\n",
      "  -0.7005951 ]\n",
      " [ 2.05009465  2.62911053  2.511049   ...  2.18141377  1.91348145\n",
      "   1.71611814]\n",
      " [-0.42724016 -0.46083979 -0.47796343 ... -0.53999258 -0.61818247\n",
      "  -0.34045744]]\n",
      "['pixel_0', 'pixel_1', 'pixel_2', 'pixel_3', 'pixel_4', 'pixel_5', 'pixel_6', 'pixel_7', 'pixel_8', 'pixel_9', 'pixel_10', 'pixel_11', 'pixel_12', 'pixel_13', 'pixel_14', 'pixel_15', 'pixel_16', 'pixel_17', 'pixel_18', 'pixel_19', 'pixel_20', 'pixel_21', 'pixel_22', 'pixel_23', 'pixel_24', 'pixel_25', 'pixel_26', 'pixel_27', 'pixel_28', 'pixel_29', 'pixel_30', 'pixel_31', 'pixel_32', 'pixel_33', 'pixel_34', 'pixel_35', 'pixel_36', 'pixel_37', 'pixel_38', 'pixel_39', 'pixel_40', 'pixel_41', 'pixel_42', 'pixel_43', 'pixel_44', 'pixel_45', 'pixel_46', 'pixel_47', 'pixel_48', 'pixel_49']\n"
     ]
    }
   ],
   "source": [
    "print(X_selected)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes treinadas pelo modelo: [2 4 7]\n",
      "Dimensões dos coeficientes (pesos) do modelo: (classes, pixels) (3, 50)\n",
      "Dimensões dos interceptos (viés) do modelo: (3,)\n"
     ]
    }
   ],
   "source": [
    "# 5. Treinando o modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)  # Criando um modelo de regressão logística\n",
    "model.fit(X_selected, y)  # Treinando o modelo com os dados selecionados e normalizados\n",
    "\n",
    "# 6. Verificando as classes treinadas imprimindo na tela as classes treinadas pelo modelo\n",
    "print(\"Classes treinadas pelo modelo:\", model.classes_)\n",
    "\n",
    "# 7. Verificando as dimensões dos coeficientes e interceptos\n",
    "print(\"Dimensões dos coeficientes (pesos) do modelo: (classes, pixels)\", model.coef_.shape)\n",
    "\n",
    "''' pesos o resultado seria uma tupla com 2 numeros o primeiro é a quantidade de classes\n",
    "    o segundo a quantidade de pixels depois de ter sido selecionados com o SelectKBest\n",
    "    para selecionar os 50 pixels mais informativos para a classificação.'''\n",
    "\n",
    "print(\"Dimensões dos interceptos (viés) do modelo:\", model.intercept_.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Função para criar uma explicação minimal usando Z3 Solver\n",
    "def minimal_explanation(model, instance, target_class, epsilon=0.2, timeout=60000):\n",
    "    \n",
    "    num_features = instance.shape[0]  # Número de recursos na instância (pixels selecionados)\n",
    "    weights = model.coef_  # Obtendo a matriz - Pesos do modelo (coeficientes)\n",
    "    intercepts = model.intercept_  # Interceptos do modelo (viés)\n",
    "    \n",
    "    # Z3 Optimize\n",
    "    opt = Optimize()  # Criando um objeto Optimize para o Z3 Solver\n",
    "    opt.set(\"timeout\", timeout)  # Definindo um limite de tempo para o solver (60000 milissegundos = 1 minuto) para não demorar muito\n",
    "    \n",
    "    # Variáveis Z3 (representando a seleção de recursos)\n",
    "    feature_selection = [Bool(f'f{i}') for i in range(num_features)]  # Criando variáveis booleanas para cada recurso (pixel)\n",
    "\n",
    "    # Função de decisão do modelo (usada para definir as restrições do Z3)\n",
    "    def decision_function(weights, intercept, instance, selected_features):\n",
    "        return Sum([If(selected_features[i], instance[i] * weights[i], 0) for i in range(num_features)]) + intercept\n",
    "    ''' Define a função de decisão do modelo que calcula a soma ponderada das características selecionadas mais o intercepto. Se a característica não for selecionada, contribui com 0.'''\n",
    "    # Obter o índice da classe alvo\n",
    "    target_index = np.where(model.classes_ == target_class)[0][0]  # Encontrando o índice da classe alvo\n",
    "\n",
    "    # Adicionar restrições ao solver\n",
    "    '''model.classes_: Lista ou array contendo todas as classes que o modelo pode prever.\n",
    "        target_index: Índice da classe alvo para a qual estamos explicando a previsão.\n",
    "        weights: Pesos do modelo para cada classe (matriz de coeficientes).\n",
    "        intercepts: Interceptos do modelo para cada classe (bias).\n",
    "        instance: Instância de entrada que está sendo explicada.\n",
    "        feature_selection: Lista de variáveis booleanas representando se uma característica (pixel) está sendo selecionada ou não.\n",
    "        epsilon: Valor de folga para a restrição, garantindo uma margem entre as decisões de classes diferentes.'''\n",
    "    for i in range(len(model.classes_)): # iterando sobre todas as classes de 0 até len(model.classes_)\n",
    "        if i != target_index:  # Verifica se o índice atual (i) não é igual ao target_index. Isso é feito porque queremos comparar a classe alvo com todas as outras classes, não com ela mesma.\n",
    "            decision_target = decision_function(weights[target_index], intercepts[target_index], instance, feature_selection)  \n",
    "            '''Calcula a função de decisão do modelo para a classe alvo.\n",
    "                weights[target_index] e intercepts[target_index] são os pesos e intercepto para a classe alvo.\n",
    "                decision_function calcula a soma ponderada das características selecionadas (ou zero se não selecionada) mais o intercepto.'''\n",
    "            decision_other = decision_function(weights[i], intercepts[i], instance, feature_selection)  # Calculando a função de decisão para outra classe\n",
    "            \n",
    "            # Relaxamento das Restrições: Ajuste da folga (epsilon)\n",
    "            constraint = decision_target > decision_other + epsilon  # Definindo a restrição para a função de decisão da classe alvo ser maior que a função de decisão das outras classes com uma margem (epsilon)\n",
    "            opt.add(constraint)  # Adicionando a restrição ao solver\n",
    "            \n",
    "    # Minimizar o número de características selecionadas\n",
    "    opt.minimize(Sum([If(f, 1, 0) for f in feature_selection]))  # Definindo a função de otimização para minimizar o número de recursos selecionados\n",
    "    \n",
    "    # Check satisfiability and get the model if possible\n",
    "    result = opt.check()  # Verificando se o Z3 Solver encontrou uma solução satisfazendo as restrições\n",
    "\n",
    "    if result == sat:  # Se o solver encontrou uma solução\n",
    "        m = opt.model()  # Obtendo o modelo (interpretação) do solver\n",
    "        explanation = [i for i in range(num_features) if m.evaluate(feature_selection[i])]  # Identificando os recursos (pixels) selecionados na explicação minimal\n",
    "        explanation_features = [feature_names[i] for i in explanation]  # Obtendo os nomes dos recursos (pixels) selecionados\n",
    "        return result, explanation, explanation_features  # Retornando o resultado do solver, a lista de índices dos recursos selecionados e os nomes dos recursos selecionados\n",
    "    else:  # Se o solver não encontrou uma solução\n",
    "        return result, None, None  # Retornando None para a explicação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de X: 21107 quantidade de imagens das classes selecionadas\n",
      "Colunas de X: Index(['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7',\n",
      "       'pixel8', 'pixel9', 'pixel10',\n",
      "       ...\n",
      "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
      "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
      "      dtype='object', length=784)\n",
      "Classe prevista pelo modelo para a instância: 4\n"
     ]
    }
   ],
   "source": [
    "# 9. Verificação do dataset e explicação com os dados normalizados\n",
    "print(f\"Tamanho de X: {len(X)} quantidade de imagens das classes selecionadas\") # Verifica o tamanho de X (imagens)\n",
    "print(f\"Colunas de X: {X.columns}\") # Imprime as colunas de X\n",
    "instance_index = 0 # Escolha um índice de instância válido (menor que o tamanho de X)\n",
    "instance = X.iloc[instance_index].to_numpy()  # Selecionando a instância (imagem) do conjunto de dados e convertendo para array numpy\n",
    "target_class = model.predict([X_selected[instance_index]])[0]  # Obtendo a classe prevista pelo modelo para a instância\n",
    "\n",
    "print(\"Classe prevista pelo modelo para a instância:\", target_class)\n",
    "\n",
    "# Calcula a explicação minimal usando os dados normalizados\n",
    "result, explanation, explanation_features = minimal_explanation(model, X_selected[instance_index], target_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explanation:\n",
    "    print(\"Objective: Minimize selected features\")\n",
    "    print(\"Solver result:\", result)\n",
    "    print(\"Model found. Explanation (indices):\", explanation)\n",
    "    print(\"Explicação minimal (nomes das características):\", explanation_features)\n",
    "\n",
    "    # Plota a imagem com os pixels irrelevantes em vermelho\n",
    "    plt.imshow(instance.reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # Pinta de vermelho os pixels irrelevantes (não presentes na explicação minimal)\n",
    "    for i in range(len(instance)):\n",
    "        if i not in explanation:\n",
    "            row = i // 28  # Calcula a linha do pixel\n",
    "            col = i % 28  # Calcula a coluna do pixel\n",
    "            plt.scatter(col, row, color='red', marker='s', s=50)\n",
    "\n",
    "    plt.title(f\"Classe Prevista: {target_class}, Pixels irrelevantes em Vermelho\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No solution found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
