{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleilsonpedro\\AppData\\Local\\Temp\\ipykernel_19796\\1089075391.py:20: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_class_0 = y[y == 0][:num_samples]\n",
      "C:\\Users\\gleilsonpedro\\AppData\\Local\\Temp\\ipykernel_19796\\1089075391.py:22: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_class_1 = y[y == 1][:num_samples]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m instance \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Exemplo de instância para explicar\u001b[39;00m\n\u001b[0;32m     77\u001b[0m target_class \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([instance])[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Classe prevista pelo modelo\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m result, explanation, explanation_features \u001b[38;5;241m=\u001b[39m \u001b[43mminimal_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explanation:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective: Minimize selected features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m, in \u001b[0;36mminimal_explanation\u001b[1;34m(model, instance, target_class, epsilon, timeout)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m target_class:\n\u001b[0;32m     56\u001b[0m     decision_target \u001b[38;5;241m=\u001b[39m decision_function(weights[target_class], intercepts[target_class], instance, feature_selection)\n\u001b[1;32m---> 57\u001b[0m     decision_other \u001b[38;5;241m=\u001b[39m decision_function(\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, intercepts[i], instance, feature_selection)\n\u001b[0;32m     58\u001b[0m     constraint \u001b[38;5;241m=\u001b[39m decision_target \u001b[38;5;241m>\u001b[39m decision_other \u001b[38;5;241m+\u001b[39m epsilon\n\u001b[0;32m     59\u001b[0m     opt\u001b[38;5;241m.\u001b[39madd(constraint)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from z3 import *\n",
    "\n",
    "# Carregando o dataset MNIST e selecionando apenas as classes 0 e 1\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(np.int8)\n",
    "\n",
    "# Selecionar apenas as classes 0 e 1\n",
    "mask = (y == 0) | (y == 1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Reduzir para as primeiras 1000 amostras (500 de cada classe, se possível)\n",
    "num_samples = 500\n",
    "X_class_0 = X[y == 0][:num_samples]\n",
    "y_class_0 = y[y == 0][:num_samples]\n",
    "X_class_1 = X[y == 1][:num_samples]\n",
    "y_class_1 = y[y == 1][:num_samples]\n",
    "\n",
    "X = np.vstack((X_class_0, X_class_1))\n",
    "y = np.hstack((y_class_0, y_class_1))\n",
    "feature_names = [f'pixel_{i}' for i in range(X.shape[1])]  # Nomes das características (pixels)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Treinando o modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Função para criar uma explicação minimal usando Z3 Solver\n",
    "def minimal_explanation(model, instance, target_class, epsilon=1e-6, timeout=60000):\n",
    "    num_features = instance.shape[0]\n",
    "    weights = model.coef_\n",
    "    intercepts = model.intercept_\n",
    "    \n",
    "    # Z3 Optimize\n",
    "    opt = Optimize()\n",
    "    opt.set(\"timeout\", timeout)  # Adiciona limite de tempo (em milissegundos)\n",
    "    \n",
    "    # Variáveis Z3\n",
    "    feature_selection = [Bool(f'f{i}') for i in range(num_features)]\n",
    "    \n",
    "    # Função de decisão do modelo\n",
    "    def decision_function(weights, intercept, instance, selected_features):\n",
    "        return Sum([If(selected_features[i], instance[i] * weights[i], 0) for i in range(num_features)]) + intercept\n",
    "    \n",
    "    # Adicionar restrições ao solver\n",
    "    for i in range(len(model.classes_)):\n",
    "        if i != target_class:\n",
    "            decision_target = decision_function(weights[target_class], intercepts[target_class], instance, feature_selection)\n",
    "            decision_other = decision_function(weights[i], intercepts[i], instance, feature_selection)\n",
    "            constraint = decision_target > decision_other + epsilon\n",
    "            opt.add(constraint)\n",
    "    \n",
    "    # Minimizar o número de características selecionadas\n",
    "    opt.minimize(Sum([If(f, 1, 0) for f in feature_selection]))\n",
    "\n",
    "    # Check satisfiability and get the model if possible\n",
    "    result = opt.check()\n",
    "    \n",
    "    if result == sat:\n",
    "        m = opt.model()\n",
    "        explanation = [i for i in range(num_features) if m.evaluate(feature_selection[i])]\n",
    "        explanation_features = [feature_names[i] for i in explanation]  # Nomes das características\n",
    "        return result, explanation, explanation_features\n",
    "    else:\n",
    "        return result, None, None\n",
    "\n",
    "# Exemplo de uso\n",
    "instance = X[0]  # Exemplo de instância para explicar\n",
    "target_class = model.predict([instance])[0]  # Classe prevista pelo modelo\n",
    "\n",
    "result, explanation, explanation_features = minimal_explanation(model, instance, target_class)\n",
    "if explanation:\n",
    "    print(\"Objective: Minimize selected features\")\n",
    "    print(\"Solver result:\", result)\n",
    "    print(\"Model found. Explanation (indices):\", explanation)\n",
    "    print(\"Explicação minimal (nomes das características):\", explanation_features)\n",
    "else:\n",
    "    print(\"No solution found\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
