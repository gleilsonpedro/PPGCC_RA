{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7088652578943647, 0.7697645172444486, 5.2254240521431345, 1.2983454980344349]\n",
      "[(2, 5.2254240521431345), (3, 1.2983454980344349), (1, 0.7697645172444486), (0, 0.7088652578943647)]\n",
      "PI-Explicação: \n",
      "- petal length (cm) - 4.7\n",
      "- petal width (cm) - 1.2\n",
      "- sepal width (cm) - 2.8\n",
      "- sepal length (cm) - 6.1\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names) # organizando em um df\n",
    "df['target'] = iris.target # rotulos\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "modelo = LogisticRegression(max_iter=200)\n",
    "modelo.fit(X_train, y_train) # treinando o modelo\n",
    "\n",
    "\n",
    "w = modelo.coef_[0] # pesos do modelo treinado\n",
    "Vs = X_test.iloc[0].to_dict() # utilizxando a primeira instância dos dados de teste \n",
    "\n",
    "delta = []\n",
    "\n",
    "# Calcula o valor delta para cada feature\n",
    "# peso negativo, valor menor = maior possibilidade da instância peetencer a classe\n",
    "# delta c\\ peso positivo é (valor feature na instancia - valor min da feature no dataset) * o peso da feature \n",
    "# delta c\\ peso negativo é (vvalor max da feature no dataset - valor feature na instancia - ) * o peso da feature\n",
    "for i, feature in enumerate(df.columns[:-1]):  \n",
    "    if w[i] < 0:\n",
    "        delta.append((Vs[feature] - df[feature].max()) * w[i])\n",
    "    else:\n",
    "        delta.append((Vs[feature] - df[feature].min()) * w[i])\n",
    "\n",
    "# Calcula o limiar (-Gamma_w)\n",
    "\n",
    "R = sum(delta) # \"(Vs predição da regressão loghistica)  # Usando a equação 13 do artigo e garantindo que R seja positivo\n",
    "# R = O valor absoluto da soma de todos os deltas\n",
    "\n",
    "def one_explanation(Vs, delta, R):\n",
    "    Xpl = []  # Inicializa a lista de PI-explicação\n",
    "    # Ordena o delta junto com seus índices, em ordem decrescente de valor absoluto\n",
    "    print(delta)\n",
    "    delta_sorted = sorted(enumerate(delta), key=lambda x: abs(x[1]), reverse=True) # enumerando os valores de delta em tuplas e ordenanas\n",
    "    print(delta_sorted)                                                                               # func lambda recebe a tupla produzida com o valor absoluto em ordem decrescente, do maior para o menor.\n",
    "    R_atual = R  # Inicializa o limiar atual\n",
    "    Idx = 0  # Inicializa o índice para iterar\n",
    "    \n",
    "    # Limite para considerar uma feature como importante, com base no limar R\n",
    "    # threshold_delta = 0 * R # Valor de delta mínimo para ser considerado relevante\n",
    "    \n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        sorted_idx, delta_value = delta_sorted[Idx]  # Desempacota o índice(soted_idx) e o valor(delta_value) do delta de acordo com o indce(idx)\n",
    "        feature = X_test.columns[sorted_idx]  # Obtém o nome da feature correspondente\n",
    "        feature_value = Vs[feature]  # Obtém o valor da feature na instância Vs\n",
    "        \n",
    "        # Adiciona à explicação apenas se o delta for maior que o threshold que está sendo calculado com uma % do R. não sei se esta certo isso\n",
    "       # if abs(delta_value) > threshold_delta:  # Verifica se o delta tem impacto relevante \n",
    "        Xpl.append(f\"{feature} - {feature_value}\")  # Adiciona feature e valor à explicação\n",
    "        \n",
    "        R_atual -= delta_value  # Atualiza o limiar atual para manter ou parar o loop\n",
    "        Idx += 1  # Incrementa o índice também para o loop\n",
    "    \n",
    "    return Xpl  # Retorna a PI-explicação\n",
    "\n",
    "# Computa a PI-explicação\n",
    "Xpl = one_explanation(Vs, delta, R)\n",
    "\n",
    "#print(f\"Pesos: {w}\")\n",
    "#print(f\"Delta: {delta}\")\n",
    "#print(f\"Limiar R: {R:.2f}\")\n",
    "#print(f\"Vs: {Vs}\\n\")\n",
    "print(f\"PI-Explicação: \")\n",
    "for item in Xpl:\n",
    "    print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8277146135745481\n",
      "Probabilidades: [0.00380009 0.82771461 0.16848529]\n",
      "Classe verdadeira: 1\n",
      "Valor de gamma_A: 0.8277146135745481\n",
      "PI-Explicação: \n",
      "- petal length (cm) - 4.7\n",
      "- petal width (cm) - 1.2\n",
      "- sepal width (cm) - 2.8\n"
     ]
    }
   ],
   "source": [
    "#ANALISANDO COMPLETO UMA ÚNICA INSTÂNCIA PARA O DATASET IRIS\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  # organizando em um DataFrame\n",
    "df['target'] = iris.target  # rótulos\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina o modelo\n",
    "modelo = LogisticRegression(max_iter=200)\n",
    "modelo.fit(X_train, y_train)  # treinando o modelo\n",
    "\n",
    "# Usa a primeira instância dos dados de teste para a explicação\n",
    "Vs = X_test.iloc[0].to_dict()  # utilizando a primeira instância dos dados de teste \n",
    "instancia_test = X_test.iloc[[0]]  # Mantem como DataFrame para preservar os nomes das características\n",
    "\n",
    "\n",
    "\n",
    "# Previsão de probabilidades para a instância\n",
    "# o predict_proba calcula a probabilidade de uma instância pertencer a uma das classes possíveis usando um modelo de classificação treinado.\n",
    "probs = modelo.predict_proba(instancia_test)[0]  # Obtém as probabilidades para cada classe\n",
    "\n",
    "# O valor de gamma_A é a probabilidade da classe verdadeira\n",
    "classe_verdadeira = y_test.iloc[0]  # Obtém a classe verdadeira da instância\n",
    "gamma_A = probs[classe_verdadeira]  # Extrai a probabilidade correspondente à classe verdadeira\n",
    "print(classe_verdadeira)\n",
    "print(gamma_A)\n",
    "# Cálculo do valor delta para cada feature\n",
    "delta = []\n",
    "w = modelo.coef_[0]  # pesos do modelo treinado\n",
    "\n",
    "# Calcula o delta para cada feature\n",
    "for i, feature in enumerate(df.columns[:-1]):\n",
    "    if w[i] < 0:\n",
    "        delta.append((Vs[feature] - df[feature].max()) * w[i])\n",
    "    else:\n",
    "        delta.append((Vs[feature] - df[feature].min()) * w[i])\n",
    "\n",
    "# Calcula R como a soma dos deltas menos gamma_A\n",
    "R = sum(delta) - gamma_A  # Atualiza R para incluir gamma_A\n",
    "\n",
    "def one_explanation(Vs, delta, R):\n",
    "    Xpl = []  # Inicializa a lista de PI-explicação\n",
    "    # Ordena o delta junto com seus índices, em ordem decrescente de valor absoluto\n",
    "    delta_sorted = sorted(enumerate(delta), key=lambda x: abs(x[1]), reverse=True)  # enumerando os valores de delta em tuplas e ordenando\n",
    "    R_atual = R  # Inicializa o limiar atual\n",
    "    Idx = 0  # Inicializa o índice para iterar\n",
    "    \n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        sorted_idx, delta_value = delta_sorted[Idx]  # Desempacota o índice e o valor do delta\n",
    "        feature = X_test.columns[sorted_idx]  # Obtém o nome da feature correspondente\n",
    "        feature_value = Vs[feature]  # Obtém o valor da feature na instância Vs\n",
    "        \n",
    "        # Adiciona à explicação\n",
    "        Xpl.append(f\"{feature} - {feature_value}\")  # Adiciona feature e valor à explicação\n",
    "        \n",
    "        R_atual -= delta_value  # Atualiza o limiar atual para manter ou parar o loop\n",
    "        Idx += 1  # Incrementa o índice\n",
    "    \n",
    "    return Xpl  # Retorna a PI-explicação\n",
    "\n",
    "# Computa a PI-explicação\n",
    "Xpl = one_explanation(Vs, delta, R)\n",
    "\n",
    "# Imprime os resultados\n",
    "print(f\"Probabilidades: {probs}\")\n",
    "print(f\"Classe verdadeira: {classe_verdadeira}\")\n",
    "print(f\"Valor de gamma_A: {gamma_A}\")\n",
    "print(f\"PI-Explicação: \")\n",
    "for item in Xpl:\n",
    "    print(f\"- {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = -3\n",
    "soma = abs(teste)\n",
    "soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes identificadas pelo modelo: [0 1 2]\n",
      "Nomes das classes: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Número total de instâncias no conjunto de teste: 30\n",
      "2\n",
      "\n",
      "Instância 2:\n",
      "Classe verdadeira: 2 (virginica)\n",
      "Probabilidades: [8.84412614e-09 1.54875125e-03 9.98451240e-01]\n",
      "Valor de gamma_A: 0.9984512399032031\n",
      "--------------------\n",
      "2\n",
      "7.7\n",
      "7.9\n",
      "4.3\n",
      "--------------------\n",
      "--------------------\n",
      "2\n",
      "2.6\n",
      "4.4\n",
      "2.0\n",
      "--------------------\n",
      "--------------------\n",
      "2\n",
      "6.9\n",
      "6.9\n",
      "1.0\n",
      "--------------------\n",
      "--------------------\n",
      "2\n",
      "2.3\n",
      "2.5\n",
      "0.1\n",
      "--------------------\n",
      "Valor de R: -0.69642094092863\n",
      "PI-Explicação:\n"
     ]
    }
   ],
   "source": [
    "# análise completa com todas as instancias do dataset\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carrega o dataset Iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  # organizando em um DataFrame\n",
    "df['target'] = iris.target  # rótulos\n",
    "\n",
    "# Divide os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina o modelo\n",
    "modelo = LogisticRegression(max_iter=200)\n",
    "modelo.fit(X_train, y_train)  # Treinando o modelo\n",
    "\n",
    "# Exibe as classes identificadas pelo modelo\n",
    "classes = modelo.classes_\n",
    "print(f\"Classes identificadas pelo modelo: {classes}\")\n",
    "print(f\"Nomes das classes: {iris['target_names']}\")\n",
    "\n",
    "# Informações sobre o dataset\n",
    "num_instancias = len(X_test)\n",
    "print(f\"\\nNúmero total de instâncias no conjunto de teste: {num_instancias}\")\n",
    "\n",
    "# Escolher qual instância analisar ou todas\n",
    "# Escolha da instância específica (por exemplo, 0) ou `None` para todas\n",
    "instancia_para_analisar = 2  \n",
    "# Operador ternàrio - se a instancia for (None) salva todas na variavel, se não adiciona somente a instância escolhida\n",
    "instancias_para_analisar = range(num_instancias) if instancia_para_analisar is None else [instancia_para_analisar]\n",
    "print(instancia_para_analisar)\n",
    "# Loop para analisar instâncias\n",
    "for idx in instancias_para_analisar:\n",
    "    Vs = X_test.iloc[idx].to_dict()  # Utilizando a instância de teste especificada\n",
    "    instancia_test = X_test.iloc[[idx]]  # Mantém como DataFrame para preservar os nomes das características\n",
    "\n",
    "    # Previsão de probabilidades para a instância\n",
    "    probs = modelo.predict_proba(instancia_test)[0]  # Obtém as probabilidades para cada classe usando o 0 para acesar a 1ª linha\n",
    "\n",
    "    # O valor de gamma_A é a probabilidade da (classe verdadeira - é o rotulo original do dataset o qual pertence a instância)\n",
    "    classe_verdadeira = y_test.iloc[idx]  # Obtém a classe verdadeira da instância\n",
    "    gamma_A = probs[classe_verdadeira]  # Extrai a probabilidade correspondente à classe verdadeira treinada pela reg.logistica na func predict_proba\n",
    "\n",
    "    # Exibe a classe verdadeira e as probabilidades\n",
    "    print(f\"\\nInstância {idx}:\")\n",
    "    print(f\"Classe verdadeira: {classe_verdadeira} ({iris['target_names'][classe_verdadeira]})\")\n",
    "    print(f\"Probabilidades: {probs}\")\n",
    "    print(f\"Valor de gamma_A: {gamma_A}\")\n",
    "\n",
    "    # Cálculo dos deltas para cada feature\n",
    "    delta = []\n",
    "    w = modelo.coef_[0]  # Pesos do modelo treinado\n",
    "\n",
    "    for i, feature in enumerate(X_train.columns):\n",
    "        if w[i] < 0:\n",
    "            delta.append((Vs[feature] - X_train[feature].max()) * w[i])\n",
    "        else:\n",
    "            delta.append((Vs[feature] - X_train[feature].min()) * w[i])\n",
    "\n",
    "        print('-'*20)\n",
    "        print(idx)\n",
    "        print(Vs[feature])\n",
    "        print(df[feature].max())\n",
    "        print(df[feature].min())\n",
    "        print('-'*20)\n",
    "\n",
    "    # Calcula R como a soma dos deltas menos gamma_A   #### no artigo não menciona se o R pode ou não ser negativo, R negativo sugere que as características                                         não estão explicando suficientemente a predição\n",
    "    \n",
    "    R = sum(delta) - gamma_A\n",
    "    #R = abs(sum(delta) - gamma_A) # a função abs alem de tratar o valor absoluto permite sempre o resultado ser positivo ou seja ela remove o simbolo negativo, porem acredito que está calculando errado\n",
    "\n",
    "    #R = max(0, sum(delta) - gamma_A)\n",
    "\n",
    "   \n",
    "    # Computa a PI-explicação\n",
    "    Xpl = []\n",
    "    delta_sorted = sorted(enumerate(delta), key=lambda x: abs(x[1]), reverse=True)\n",
    "    R_atual = R\n",
    "    Idx = 0\n",
    "\n",
    "    # Calcula a explicação\n",
    "    while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "        sorted_idx, delta_value = delta_sorted[Idx]\n",
    "        feature = X_test.columns[sorted_idx]  # Nome da feature correspondente\n",
    "        feature_value = Vs[feature]  # Valor da feature para a instância\n",
    "\n",
    "        # Adiciona à explicação\n",
    "        Xpl.append(f\"{feature} - {feature_value}\")\n",
    "\n",
    "        R_atual -= delta_value\n",
    "        Idx += 1\n",
    "\n",
    "    # Imprime a PI-explicação\n",
    "    print(f\"Valor de R: {R}\")\n",
    "    print(\"PI-Explicação:\")\n",
    "    for item in Xpl:\n",
    "        print(f\"- {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes identificadas pelo modelo: [0 1 2]\n",
      "\n",
      "Instância 0:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.00380009 0.82771461 0.16848529]\n",
      "Valor de gamma_A: 0.8277146135745481\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.7\n",
      "- petal width (cm) - 1.2\n",
      "- sepal width (cm) - 2.8\n",
      "\n",
      "Instância 1:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.46946389e-01 5.30534119e-02 1.99072566e-07]\n",
      "Valor de gamma_A: 0.9469463890124217\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.7\n",
      "- petal width (cm) - 0.3\n",
      "- sepal width (cm) - 3.8\n",
      "\n",
      "Instância 2:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [8.84412614e-09 1.54875125e-03 9.98451240e-01]\n",
      "Valor de gamma_A: 0.9984512399032031\n",
      "PI-Explicação:\n",
      "\n",
      "Instância 3:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.00647972 0.79218894 0.20133134]\n",
      "Valor de gamma_A: 0.7921889445681916\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.5\n",
      "- petal width (cm) - 1.5\n",
      "- sepal width (cm) - 2.9\n",
      "\n",
      "Instância 4:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.0014558  0.77408417 0.22446003]\n",
      "Valor de gamma_A: 0.7740841723664624\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.8\n",
      "- petal width (cm) - 1.4\n",
      "- sepal width (cm) - 2.8\n",
      "\n",
      "Instância 5:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.55892926e-01 4.41068973e-02 1.76245156e-07]\n",
      "Valor de gamma_A: 0.9558929264540175\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.5\n",
      "- petal width (cm) - 0.4\n",
      "- sepal width (cm) - 3.4\n",
      "- sepal length (cm) - 5.4\n",
      "\n",
      "Instância 6:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.07798058 0.90772975 0.01428968]\n",
      "Valor de gamma_A: 0.9077297459027671\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 3.6\n",
      "- petal width (cm) - 1.3\n",
      "- sepal length (cm) - 5.6\n",
      "\n",
      "Instância 7:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [1.63599794e-04 1.54513682e-01 8.45322719e-01]\n",
      "Valor de gamma_A: 0.8453227185370474\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.1\n",
      "- sepal width (cm) - 3.1\n",
      "\n",
      "Instância 8:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.0022223  0.76282917 0.23494854]\n",
      "Valor de gamma_A: 0.7628291654060669\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.5\n",
      "- petal width (cm) - 1.5\n",
      "- sepal length (cm) - 6.2\n",
      "\n",
      "Instância 9:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.02842321 0.94574328 0.02583352]\n",
      "Valor de gamma_A: 0.9457432757170777\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 3.9\n",
      "- petal width (cm) - 1.2\n",
      "- sepal length (cm) - 5.8\n",
      "\n",
      "Instância 10:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [4.44831339e-04 2.42505079e-01 7.57050090e-01]\n",
      "Valor de gamma_A: 0.7570500899269109\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.1\n",
      "- sepal width (cm) - 3.2\n",
      "- sepal length (cm) - 6.5\n",
      "\n",
      "Instância 11:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.68132135e-01 3.18677875e-02 7.80001614e-08]\n",
      "Valor de gamma_A: 0.9681321345243881\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.4\n",
      "- petal width (cm) - 0.1\n",
      "- sepal length (cm) - 4.8\n",
      "\n",
      "Instância 12:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.72999958e-01 2.70000085e-02 3.32236410e-08]\n",
      "Valor de gamma_A: 0.9729999582948705\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.3\n",
      "- petal width (cm) - 0.2\n",
      "- sepal width (cm) - 3.5\n",
      "\n",
      "Instância 13:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.61911090e-01 3.80887992e-02 1.10778595e-07]\n",
      "Valor de gamma_A: 0.9619110900146416\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.5\n",
      "- petal width (cm) - 0.1\n",
      "- sepal length (cm) - 4.9\n",
      "- sepal width (cm) - 3.1\n",
      "\n",
      "Instância 14:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.79282277e-01 2.07176589e-02 6.45316733e-08]\n",
      "Valor de gamma_A: 0.9792822765211944\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.5\n",
      "- petal width (cm) - 0.3\n",
      "- sepal width (cm) - 3.8\n",
      "- sepal length (cm) - 5.1\n",
      "\n",
      "Instância 15:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.0045892  0.71230366 0.28310714]\n",
      "Valor de gamma_A: 0.712303664317477\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.7\n",
      "- sepal width (cm) - 3.3\n",
      "- petal width (cm) - 1.6\n",
      "\n",
      "Instância 16:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [7.30629872e-06 2.41354954e-02 9.75857198e-01]\n",
      "Valor de gamma_A: 0.9758571983220468\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.8\n",
      "- sepal width (cm) - 3.0\n",
      "\n",
      "Instância 17:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.02735008 0.94777218 0.02487774]\n",
      "Valor de gamma_A: 0.9477721799344782\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 3.9\n",
      "- petal width (cm) - 1.1\n",
      "- sepal length (cm) - 5.6\n",
      "\n",
      "Instância 18:\n",
      "Classe verdadeira: 1 (Classe 1)\n",
      "Probabilidades: [0.00825559 0.83165055 0.16009386]\n",
      "Valor de gamma_A: 0.8316505510103394\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.5\n",
      "- petal width (cm) - 1.3\n",
      "- sepal length (cm) - 5.7\n",
      "\n",
      "Instância 19:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [1.43435320e-05 3.58355711e-02 9.64150085e-01]\n",
      "Valor de gamma_A: 0.9641500853638135\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.6\n",
      "- sepal width (cm) - 2.8\n",
      "\n",
      "Instância 20:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.64175552e-01 3.58242553e-02 1.92627306e-07]\n",
      "Valor de gamma_A: 0.9641755520813469\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.6\n",
      "- petal width (cm) - 0.2\n",
      "- sepal length (cm) - 4.7\n",
      "- sepal width (cm) - 3.2\n",
      "\n",
      "Instância 21:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [0.00132595 0.39885912 0.59981492]\n",
      "Valor de gamma_A: 0.5998149238983429\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 4.9\n",
      "- sepal width (cm) - 3.0\n",
      "- sepal length (cm) - 6.1\n",
      "- petal width (cm) - 1.8\n",
      "\n",
      "Instância 22:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.61607313e-01 3.83924266e-02 2.60481913e-07]\n",
      "Valor de gamma_A: 0.9616073129414248\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.6\n",
      "- petal width (cm) - 0.4\n",
      "- sepal width (cm) - 3.4\n",
      "- sepal length (cm) - 5.0\n",
      "\n",
      "Instância 23:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [1.87325361e-05 4.57691073e-02 9.54212160e-01]\n",
      "Valor de gamma_A: 0.9542121601910569\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.6\n",
      "- sepal width (cm) - 2.8\n",
      "- sepal length (cm) - 6.4\n",
      "\n",
      "Instância 24:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [1.66336751e-06 2.56958289e-02 9.74302508e-01]\n",
      "Valor de gamma_A: 0.9743025077061386\n",
      "PI-Explicação:\n",
      "- sepal width (cm) - 3.8\n",
      "- petal length (cm) - 6.4\n",
      "\n",
      "Instância 25:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [9.44103189e-05 1.04372646e-01 8.95532943e-01]\n",
      "Valor de gamma_A: 0.8955329432369129\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.2\n",
      "- sepal width (cm) - 3.0\n",
      "\n",
      "Instância 26:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [8.77331336e-06 5.83497347e-02 9.41641492e-01]\n",
      "Valor de gamma_A: 0.9416414920258596\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.8\n",
      "- petal width (cm) - 1.8\n",
      "- sepal width (cm) - 2.5\n",
      "\n",
      "Instância 27:\n",
      "Classe verdadeira: 2 (Classe 2)\n",
      "Probabilidades: [4.35267960e-06 1.87572310e-02 9.81238416e-01]\n",
      "Valor de gamma_A: 0.9812384162928816\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 5.9\n",
      "- sepal width (cm) - 3.2\n",
      "\n",
      "Instância 28:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.66727322e-01 3.32725425e-02 1.35626700e-07]\n",
      "Valor de gamma_A: 0.9667273218938974\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.4\n",
      "- petal width (cm) - 0.3\n",
      "- sepal length (cm) - 4.8\n",
      "\n",
      "Instância 29:\n",
      "Classe verdadeira: 0 (Classe 0)\n",
      "Probabilidades: [9.56089844e-01 4.39099238e-02 2.32108518e-07]\n",
      "Valor de gamma_A: 0.9560898440568257\n",
      "PI-Explicação:\n",
      "- petal length (cm) - 1.6\n",
      "- petal width (cm) - 0.2\n",
      "- sepal length (cm) - 4.8\n",
      "- sepal width (cm) - 3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df_iris['target'] = iris.target\n",
    "\n",
    "def pi_explanation(dataset, target_col, instance_index=None):\n",
    "    # Divide os dados em características (X) e rótulos (y)\n",
    "    X = dataset.drop(target_col, axis=1)\n",
    "    y = dataset[target_col]\n",
    "\n",
    "    # Divide os dados em conjunto de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Treina o modelo de regressão logística\n",
    "    modelo = LogisticRegression(max_iter=200)\n",
    "    modelo.fit(X_train, y_train)  # Treinando o modelo\n",
    "\n",
    "    # Exibe as classes possíveis\n",
    "    classes = modelo.classes_  # Identifica as classes\n",
    "    print(f\"Classes identificadas pelo modelo: {classes}\")\n",
    "\n",
    "    # Define quais instâncias serão analisadas (todas ou uma específica)\n",
    "    if instance_index is not None:\n",
    "        instances_to_analyze = [instance_index]  # Analisar apenas a instância especificada\n",
    "    else:\n",
    "        instances_to_analyze = range(len(X_test))  # Analisar todas as instâncias\n",
    "\n",
    "    # Loop para analisar uma ou mais instâncias\n",
    "    for idx in instances_to_analyze:\n",
    "        Vs = X_test.iloc[idx].to_dict()  # Utilizando a instância de teste especificada\n",
    "        instancia_test = X_test.iloc[[idx]]  # Mantém como DataFrame para preservar os nomes das características\n",
    "\n",
    "        # Previsão de probabilidades para a instância\n",
    "        probs = modelo.predict_proba(instancia_test)[0]  # Obtém as probabilidades para cada classe\n",
    "\n",
    "        # O valor de gamma_A é a probabilidade da classe verdadeira\n",
    "        classe_verdadeira = y_test.iloc[idx]  # Obtém a classe verdadeira da instância\n",
    "        gamma_A = probs[classe_verdadeira]  # Extrai a probabilidade correspondente à classe verdadeira\n",
    "\n",
    "        # Exibe a classe verdadeira e as probabilidades\n",
    "        print(f\"\\nInstância {idx}:\")\n",
    "        print(f\"Classe verdadeira: {classe_verdadeira} (Classe {classes[classe_verdadeira]})\")\n",
    "        print(f\"Probabilidades: {probs}\")\n",
    "        print(f\"Valor de gamma_A: {gamma_A}\")\n",
    "\n",
    "        # Cálculo dos deltas para cada feature\n",
    "        delta = []\n",
    "        w = modelo.coef_[0]  # Pesos do modelo treinado\n",
    "\n",
    "        for i, feature in enumerate(X.columns):\n",
    "            if w[i] < 0:\n",
    "                delta.append((Vs[feature] - X[feature].max()) * w[i])\n",
    "            else:\n",
    "                delta.append((Vs[feature] - X[feature].min()) * w[i])\n",
    "\n",
    "        # Calcula R como a soma dos deltas menos gamma_A\n",
    "        R = sum(delta) - gamma_A\n",
    "\n",
    "        # Função para computar a PI-explicação\n",
    "        def one_explanation(Vs, delta, R):\n",
    "            Xpl = []  # Inicializa a lista de PI-explicação\n",
    "            delta_sorted = sorted(enumerate(delta), key=lambda x: abs(x[1]), reverse=True)  # Ordena os deltas\n",
    "            R_atual = R  # Inicializa o limiar atual\n",
    "            Idx = 0  # Inicializa o índice para iterar\n",
    "\n",
    "            while R_atual >= 0 and Idx < len(delta_sorted):\n",
    "                sorted_idx, delta_value = delta_sorted[Idx]  # Desempacota o índice e o valor do delta\n",
    "                feature = X_test.columns[sorted_idx]  # Obtém o nome da feature correspondente\n",
    "                feature_value = Vs[feature]  # Obtém o valor da feature na instância Vs\n",
    "\n",
    "                # Adiciona à explicação\n",
    "                Xpl.append(f\"{feature} - {feature_value}\")\n",
    "\n",
    "                R_atual -= delta_value  # Atualiza o limiar atual\n",
    "                Idx += 1  # Incrementa o índice\n",
    "            \n",
    "            return Xpl  # Retorna a PI-explicação\n",
    "\n",
    "        # Computa a PI-explicação para a instância\n",
    "        Xpl = one_explanation(Vs, delta, R)\n",
    "\n",
    "        # Imprime a PI-explicação\n",
    "        print(\"PI-Explicação:\")\n",
    "        for item in Xpl:\n",
    "            print(f\"- {item}\")\n",
    "\n",
    "\n",
    "\n",
    "# Chamada da função para analisar todas as instâncias\n",
    "pi_explanation(df_iris, target_col='target', instance_index=None)  # Para todas as instâncias\n",
    "\n",
    "# Chamada da função para analisar uma instância específica\n",
    "# pi_explanation(df_iris, target_col='target', instance_index=0)  # Para a instância 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
