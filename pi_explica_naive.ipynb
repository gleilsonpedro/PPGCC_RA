{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI-explicação Log-Linear para a instância [6.  2.7 5.1 1.6]: [('petal length (cm)', 5.1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregando e preparando o dataset Iris com duas classes\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_data['class'] = iris.target\n",
    "iris_data = iris_data[iris_data['class'].isin([0, 1])]  # Mantém apenas as classes 0 e 1\n",
    "\n",
    "# Separando os dados de treino e teste\n",
    "X = iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "y = iris_data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinando o modelo de Regressão Logística\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "def calculate_pi_explanation_loglinear(instance, clf, features):\n",
    "    \"\"\"Calcula uma PI-explicação de menor tamanho para uma instância utilizando um algoritmo log-linear.\n",
    "\n",
    "    Args:\n",
    "        instance: A instância para a qual se deseja calcular a PI-explicação (array NumPy de uma única linha).\n",
    "        clf: O classificador de Regressão Logística treinado.\n",
    "        features: Nomes dos atributos do conjunto de dados.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de pares valor-atributo que constituem a PI-explicação.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula a probabilidade da classe prevista\n",
    "    predicted_class = clf.predict(instance.reshape(1, -1))[0]\n",
    "    prob_predicted_class = clf.predict_proba(instance.reshape(1, -1))[0][predicted_class]\n",
    "\n",
    "    # Calcula a probabilidade da outra classe\n",
    "    prob_other_class = clf.predict_proba(instance.reshape(1, -1))[0][1 - predicted_class]\n",
    "\n",
    "    # Calcula a diferença de probabilidade para cada atributo\n",
    "    delta_features = [(feature,\n",
    "                       abs(clf.coef_[0][i] * instance[i]))\n",
    "                      for i, feature in enumerate(features)]\n",
    "\n",
    "    # Ordena os atributos pela diferença de probabilidade (maior primeiro)\n",
    "    delta_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Seleciona os atributos que contribuem para a classe prevista\n",
    "    pi_explanation = []\n",
    "    threshold = prob_predicted_class - prob_other_class\n",
    "    current_threshold = 0\n",
    "    for idx, (feature, delta) in enumerate(delta_features): \n",
    "        current_threshold += delta\n",
    "        pi_explanation.append((feature, instance[features.index(feature)]))\n",
    "        if current_threshold > threshold:\n",
    "            break\n",
    "\n",
    "    return pi_explanation\n",
    "\n",
    "# Selecionando a primeira instância do conjunto de teste como um array NumPy\n",
    "instance = X_test.iloc[0].to_numpy()\n",
    "\n",
    "# Calculando a PI-explicação para a instância\n",
    "pi_explanation = calculate_pi_explanation_loglinear(instance, clf, list(X.columns))\n",
    "\n",
    "# Exibindo a PI-explicação\n",
    "print(f\"PI-explicação Log-Linear para a instância {instance}: {pi_explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.0: Comprimento da sépala (sepal length) em centímetros.\n",
    "2.7: Largura da sépala (sepal width) em centímetros.\n",
    "5.1: Comprimento da pétala (petal length) em centímetros.\n",
    "1.6: Largura da pétala (petal width) em centímetros.\n",
    "\n",
    "A PI-explicação sugere que o comprimento da pétala é o fator mais influente para a decisão do modelo sobre essa instância específica com 5.1 cm de comprimento.\n",
    "Esse tipo de explicação ajuda a entender quais características são mais importantes para o modelo ao fazer uma previsão específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI-explicação Log-Linear para a instância [6.3 2.8 5.1 1.5]: [('petal length (cm)', 5.1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregando e preparando o dataset Iris com duas classes\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_data['class'] = iris.target\n",
    "iris_data = iris_data[iris_data['class'].isin([2, 0])]  # Mudança para classes 1 e 2\n",
    "\n",
    "# Separando os dados de treino e teste\n",
    "X = iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "y = iris_data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinando o modelo de Regressão Logística\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "def calculate_pi_explanation_loglinear(instance, clf, features):\n",
    "    \"\"\"Calcula uma PI-explicação de menor tamanho para uma instância utilizando um algoritmo log-linear.\n",
    "\n",
    "    Args:\n",
    "        instance: A instância para a qual se deseja calcular a PI-explicação (array NumPy de uma única linha).\n",
    "        clf: O classificador de Regressão Logística treinado.\n",
    "        features: Nomes dos atributos do conjunto de dados.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de pares valor-atributo que constituem a PI-explicação.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula a probabilidade das duas classes previstas\n",
    "    prob_predicted_class = clf.predict_proba(instance.reshape(1, -1))[0]\n",
    "\n",
    "    # Calcula a diferença de probabilidade para cada atributo\n",
    "    delta_features = []\n",
    "    for i, feature in enumerate(features):\n",
    "        coef = clf.coef_[0][i]  # Coeficiente do modelo para o atributo atual\n",
    "        value = instance[i]     # Valor do atributo na instância atual\n",
    "        delta = abs(coef * value)\n",
    "        delta_features.append((feature, delta))\n",
    "\n",
    "\n",
    "    # Ordena os atributos pela diferença de probabilidade (maior primeiro)\n",
    "    delta_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Seleciona os atributos que contribuem para a classe prevista\n",
    "    pi_explanation = []\n",
    "    threshold = abs(prob_predicted_class[0] - prob_predicted_class[1])  # Diferença de probabilidade entre as duas classes\n",
    "    current_threshold = 0\n",
    "    for idx, (feature, delta) in enumerate(delta_features): \n",
    "        current_threshold += delta\n",
    "        pi_explanation.append((feature, instance[features.index(feature)]))\n",
    "        if current_threshold > threshold:\n",
    "            break\n",
    "\n",
    "    return pi_explanation\n",
    "\n",
    "# Selecionando a primeira instância do conjunto de teste como um array NumPy\n",
    "instance = X_test.iloc[0].to_numpy()\n",
    "\n",
    "# Calculando a PI-explicação para a instância\n",
    "pi_explanation = calculate_pi_explanation_loglinear(instance, clf, list(X.columns))\n",
    "\n",
    "# Exibindo a PI-explicação\n",
    "print(f\"PI-explicação Log-Linear para a instância {instance}: {pi_explanation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
