{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dataset, adicionando os dados em um dataframe fltrando as para trabalhanr somente com a classe 0 e 1\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_data['class'] = iris.target\n",
    "iris_data = iris_data[iris_data['class'].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizando os atributos do Iris para usar MultinomialNB\n",
    "for col in iris_data.columns[:-1]: # iterando sobre todas as colunas exceto a coluna class\n",
    "    iris_data[col] = pd.cut(iris_data[col], bins=3, labels=False, include_lowest=True, duplicates='drop')\n",
    "    # iris_data[col] são os dados de cada coluna\n",
    "    # bins=3 divide os dados em 3 bins (categorias)\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "y = iris_data['class']\n",
    "clf = MultinomialNB() # Usando MultinomialNB\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'feature_log_prob_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[0;32m     41\u001b[0m instance \u001b[38;5;241m=\u001b[39m iris_data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Seleciona a primeira instância\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m pi_explanation \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pi_explanation_loglinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miris\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPI-explicação Log-Linear para a instância \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi_explanation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mcalculate_pi_explanation_loglinear\u001b[1;34m(instance, clf, features)\u001b[0m\n\u001b[0;32m     18\u001b[0m log_prob_other_class \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_log_proba([instance])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m predicted_class]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Calcula a diferença de probabilidade logarítmica para cada atributo\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m delta_features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredicted_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Ordena os atributos pela diferença de probabilidade logarítmica (maior primeiro)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m delta_features\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m log_prob_other_class \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_log_proba([instance])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m predicted_class]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Calcula a diferença de probabilidade logarítmica para cada atributo\u001b[39;00m\n\u001b[0;32m     21\u001b[0m delta_features \u001b[38;5;241m=\u001b[39m [(feature,\n\u001b[1;32m---> 22\u001b[0m                    \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m[predicted_class][i] \u001b[38;5;241m-\u001b[39m clf\u001b[38;5;241m.\u001b[39mfeature_log_prob_[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m predicted_class][i])\n\u001b[0;32m     23\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features)]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Ordena os atributos pela diferença de probabilidade logarítmica (maior primeiro)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m delta_features\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'feature_log_prob_'"
     ]
    }
   ],
   "source": [
    "def calculate_pi_explanation_loglinear(instance, clf, features):\n",
    "    \"\"\"Calcula uma PI-explicação de menor tamanho para uma instância utilizando um algoritmo log-linear.\n",
    "\n",
    "    Args:\n",
    "        instance: A instância para a qual se deseja calcular a PI-explicação.\n",
    "        clf: O classificador Naive Bayes treinado.\n",
    "        features: Nomes dos atributos do conjunto de dados.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de pares valor-atributo que constituem a PI-explicação.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula a probabilidade da classe prevista\n",
    "    predicted_class = clf.predict([instance])[0]\n",
    "    log_prob_predicted_class = clf.predict_log_proba([instance])[0][predicted_class]\n",
    "\n",
    "    # Calcula a probabilidade da outra classe\n",
    "    log_prob_other_class = clf.predict_log_proba([instance])[0][1 - predicted_class]\n",
    "\n",
    "    # Calcula a diferença de probabilidade logarítmica para cada atributo\n",
    "    delta_features = [(feature,\n",
    "                       clf.feature_log_prob_[predicted_class][i] - clf.feature_log_prob_[1 - predicted_class][i])\n",
    "                      for i, feature in enumerate(features)]\n",
    "\n",
    "    # Ordena os atributos pela diferença de probabilidade logarítmica (maior primeiro)\n",
    "    delta_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Seleciona os atributos que contribuem para a classe prevista\n",
    "    pi_explanation = []\n",
    "    threshold = log_prob_predicted_class - log_prob_other_class\n",
    "    current_threshold = 0\n",
    "    for feature, delta in delta_features:\n",
    "        current_threshold += delta\n",
    "        if current_threshold > threshold:\n",
    "            pi_explanation.append((feature, instance[i]))\n",
    "            break\n",
    "\n",
    "    return pi_explanation\n",
    "\n",
    "# Exemplo de uso\n",
    "instance = iris_data.iloc[0].to_list()[:-1]  # Seleciona a primeira instância\n",
    "pi_explanation = calculate_pi_explanation_loglinear(instance, clf, iris.feature_names)\n",
    "print(f\"PI-explicação Log-Linear para a instância {instance}: {pi_explanation}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_pi_explanations(instance, clf, features):\n",
    "    \"\"\"Enumera todas as PI-explicações para uma instância utilizando um algoritmo de atraso polinomial.\n",
    "\n",
    "    Args:\n",
    "        instance: A instância para a qual se deseja calcular as PI-explicações.\n",
    "        clf: O classificador Naive Bayes treinado.\n",
    "        features: Nomes dos atributos do conjunto de dados.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de todas as PI-explicações possíveis.\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_class = clf.predict([instance])[0]\n",
    "    log_prob_predicted_class = clf.predict_log_proba([instance])[0][predicted_class]\n",
    "    log_prob_other_class = clf.predict_log_proba([instance])[0][1 - predicted_class]\n",
    "\n",
    "    delta_features = [(feature,\n",
    "                       clf.feature_log_prob_[predicted_class][i] - clf.feature_log_prob_[1 - predicted_class][i])\n",
    "                      for i, feature in enumerate(features)]\n",
    "    delta_features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    pi_explanations = []\n",
    "    def backtrack(idx, current_explanation, current_threshold):\n",
    "        if current_threshold > log_prob_predicted_class - log_prob_other_class:\n",
    "            pi_explanations.append(current_explanation)\n",
    "            return\n",
    "\n",
    "        if idx >= len(delta_features):\n",
    "            return\n",
    "\n",
    "        feature, delta = delta_features[idx]\n",
    "        current_explanation.append((feature, instance[idx]))\n",
    "        backtrack(idx + 1, current_explanation.copy(), current_threshold + delta)\n",
    "        current_explanation.pop()\n",
    "        backtrack(idx + 1, current_explanation.copy(), current_threshold)\n",
    "\n",
    "    backtrack(0, [], 0)\n",
    "\n",
    "    return pi_explanations\n",
    "\n",
    "# Exemplo de uso\n",
    "instance = iris_data.iloc[1].to_list()[:-1]  # Seleciona a segunda instância\n",
    "pi_explanations = enumerate_pi_explanations(instance, clf, iris.feature_names)\n",
    "print(f\"PI-explicações com atraso polinomial para a instância {instance}: {pi_explanations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
