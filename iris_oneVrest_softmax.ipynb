{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicação Mínima para a Instância de Teste:\n",
      "Classe Prevista: setosa\n",
      "Para a classe setosa:\n",
      "sepal length (cm): -0.35218506849831155\n",
      "sepal width (cm): -0.46134731198410894\n",
      "petal length (cm): 2.628237951720523\n",
      "petal width (cm): 2.1667802503737237\n",
      "Para a classe versicolor:\n",
      "sepal length (cm): -0.16068686159326173\n",
      "sepal width (cm): -1.9091229122539757\n",
      "petal length (cm): 0.6248264270869114\n",
      "petal width (cm): -1.1434417953080562\n",
      "Para a classe virginica:\n",
      "sepal length (cm): -0.3996653809248001\n",
      "sepal width (cm): 0.8076216014439159\n",
      "petal length (cm): -2.080816560777914\n",
      "petal width (cm): -0.8798894566148193\n"
     ]
    }
   ],
   "source": [
    "''' ONE-VERSUS-REST\n",
    "\n",
    "Com uma abordagem mais simples onde um classificador binário é treinado para cada classe'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Passo 1: Treinamento do Modelo\n",
    "# Carregar conjunto de dados IRIS\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dar nome aos bois ( so pra deixar mais claro )\n",
    "class_names = iris.target_names\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "\n",
    "# Treinar modelo de regressão logística\n",
    "model = LogisticRegression(multi_class='ovr')  # Usando a estratégia \"um versus o resto\"\n",
    "model.fit(X, y)\n",
    "\n",
    "# Passo 2: Explicação Mínima\n",
    "def minimal_explanation(model, instance):\n",
    "    # Obtendo as probabilidades previstas para cada classe\n",
    "    probs = model.predict_proba(instance.reshape(1, -1)).flatten()\n",
    "    # Ordenar as probabilidades e índices das classes em ordem crescente\n",
    "    sorted_indices = np.argsort(probs)\n",
    "    sorted_probs = probs[sorted_indices]\n",
    "    # Extraindo as classes com a maior probabilidade\n",
    "    top_classes = sorted_indices[-3:]  # Pegar as três maiores probabilidades\n",
    "    # Calculando as contribuições das features para as classes principais\n",
    "    contributions = []\n",
    "    for cls in top_classes:\n",
    "        class_probs = np.zeros_like(probs) # Criando um array de zeros \n",
    "        class_probs[cls] = sorted_probs[-1] # garantindo que a probabilidade da classe sja diferente de zero\n",
    "        contributions.append((model.coef_[cls] * class_probs[cls]).flatten()) # Multiplicando o modelo pela probab. da classe para obter as contribuições das features e salvando na lista contributions.\n",
    "    return np.array(contributions) # Retornando as contribuições como array com numpy\n",
    "\n",
    "# Passo 3: Teste com IRIS Dataset\n",
    "# Selecionar uma instância de teste do conjunto de dados IRIS\n",
    "instance_index = 0\n",
    "instance = X[instance_index]\n",
    "\n",
    "# Obter explicação mínima para a instância selecionada\n",
    "explanation = minimal_explanation(model, instance)\n",
    "\n",
    "# Prever a classe para a instância de teste\n",
    "predicted_class = model.predict(instance.reshape(1, -1))\n",
    "\n",
    "# Exibir a explicação mínima\n",
    "print(\"Explicação Mínima para a Instância de Teste:\")\n",
    "print(f\"Classe Prevista: {class_names[predicted_class[0]]}\")\n",
    "for i, cls in enumerate(explanation):\n",
    "    print(f\"Para a classe {class_names[i]}:\")\n",
    "    for j, feature in enumerate(cls):\n",
    "        print(f\"{feature_names[j]}: {feature}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "com base na explicação:\n",
    "Classe Setosa:\n",
    "    características mais influentes foram Comp. da Pétala com 2.62823...\n",
    "                                          Larg. da Pétala com 2.16678...\n",
    "    as outras características foram negativas com bem menos influência\n",
    "\n",
    "Classe Versicolor:\n",
    "    características mais influentes foram Comp. da Pétala com 0.62482...\n",
    "    as outras foram negativas\n",
    "\n",
    "Classe Virínica:\n",
    "    característica mais influentes foram Largura da Sépala com 0.80762...\n",
    "    as outras foram negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicação Mínima para a Instância de Teste:\n",
      "Classe Prevista: setosa\n",
      "Para a classe 0:\n",
      "Feature 1: -0.10594283498933536\n",
      "Feature 2: -0.6384008398776853\n",
      "Feature 3: 2.6719993174241807\n",
      "Feature 4: 1.9923363818652748\n",
      "Para a classe 1:\n",
      "Feature 1: 0.5197923251415844\n",
      "Feature 2: -0.30886032735733576\n",
      "Feature 3: -0.19793195878541697\n",
      "Feature 4: -0.927740553607467\n",
      "Para a classe 2:\n",
      "Feature 1: -0.4138494901522469\n",
      "Feature 2: 0.9472611672350082\n",
      "Feature 3: -2.4740673586387945\n",
      "Feature 4: -1.064595828257813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gleilsonpedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "''' SOFTMAX\n",
    "O softmax é mais indicado para problemas de classificação multiclasse pois as previsões são expressas como probabilidades para cada classe '''\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Passo 1: Treinamento do Modelo\n",
    "# Carregar conjunto de dados IRIS\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Treinar modelo de regressão logística com a estratégia softmax\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Passo 2: Explicação Mínima\n",
    "def minimal_explanation(model, instance):\n",
    "    # Obtendo as probabilidades previstas para cada classe\n",
    "    probs = model.predict_proba(instance.reshape(1, -1)).flatten()\n",
    "    # Ordenar as probabilidades e índices das classes em ordem crescente\n",
    "    sorted_indices = np.argsort(probs)\n",
    "    sorted_probs = probs[sorted_indices]\n",
    "    # Extraindo as classes com a maior probabilidade\n",
    "    top_classes = sorted_indices[-3:]  # Pegar as três maiores probabilidades\n",
    "    # Calculando as contribuições das features para as classes principais\n",
    "    contributions = []\n",
    "    for cls in top_classes:\n",
    "        class_probs = np.zeros_like(probs)\n",
    "        class_probs[cls] = sorted_probs[-1]\n",
    "        contributions.append((model.coef_[cls] * class_probs[cls]).flatten())\n",
    "    return np.array(contributions)\n",
    "\n",
    "# Passo 3: Teste com IRIS Dataset\n",
    "# Selecionar uma instância de teste do conjunto de dados IRIS\n",
    "instance_index = 0\n",
    "instance = X[instance_index]\n",
    "\n",
    "# Obter explicação mínima para a instância selecionada\n",
    "explanation = minimal_explanation(model, instance)\n",
    "\n",
    "# Prever a classe para a instância de teste\n",
    "predicted_class = model.predict(instance.reshape(1, -1))\n",
    "\n",
    "# Exibir a explicação mínima\n",
    "print(\"Explicação Mínima para a Instância de Teste:\")\n",
    "print(f\"Classe Prevista: {class_names[predicted_class[0]]}\")\n",
    "for i, cls in enumerate(explanation):\n",
    "    print(f\"Para a classe {i}:\")\n",
    "    for j, feature in enumerate(cls):\n",
    "        print(f\"Feature {j+1}: {feature}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
